{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef027949-c23c-4e44-8696-59933df1b9fd",
   "metadata": {},
   "source": [
    "# Trying Deep Learning models for MRI-based Water-fat separation\n",
    "In this notebook, you can upload your own Chemical Shift-Encoded (CSE)-MR images and obtain the separated water-fat signals using the different DL-based models developed in this project. All of them were developed to work only with CSE-MR images obtained at **1.5T** scanners.\n",
    "\n",
    "The accepted data formats to upload your data are:\n",
    "* DICOM files\n",
    "* MAT files - using the [ISMRM Water-Fat Toolbox](https://www.ismrm.org/workshops/FatWater12/data.htm) format\n",
    "\n",
    "The available DL models for testing are:\n",
    "* U-Net\n",
    "* Multi-Decoder Water-Fat separation Network (MDWF-Net) - Refer to [DOI:10.1007/s00330-023-09576-2](https://doi.org/10.1007/s00330-023-09576-2)\n",
    "* Variable Echo Times neural Network (VET-Net) - Refer to [DOI:10.1007/s00330-024-11164-x](https://doi.org/10.1007/s00330-024-11164-x)\n",
    "* Artificial Intelligence-based Decomposition of water and fat with Echo asymmetry and Least squares estimation (AI-DEAL) - Soon to be published!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c47bb-db5c-4d36-be92-47969ae04fd0",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e60782-ce5e-4df2-b7d0-060e95c4bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from itertools import cycle\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74bc1f-eba0-4130-927c-733e63438753",
   "metadata": {},
   "source": [
    "Optionally, you can disable any available GPU. This is useful if your GPU's size is not enough to handle the data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c4a31-3ac5-4e17-bc39-5dcfe7ea2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a0c3a-44f3-4c9c-888e-0b64dc14f76a",
   "metadata": {},
   "source": [
    "Finally, we the customized libraries included in this repository are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6532dd9-fd8b-48bd-b41b-8b5cbd4b2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2lib as tl\n",
    "import DLlib as dl\n",
    "import pylib as py\n",
    "import wflib as wf\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced9452-f60b-4ce1-b034-b7f40fa3af1b",
   "metadata": {},
   "source": [
    "## Loading CSE-MRI data\n",
    "First, the dataset directory must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72642abc-c28e-449f-a89b-2fcffbb27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory - Read DICOM files\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_INTA/016/2D_NSA1_24S_2MM_IM_0007_anon/2D_NSA1_24S_2MM_IM_0007_anon.mat\"\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_JGalgani/004/2D_NSA1_24S_2MM_IM_0007_anon/2D_NSA1_24S_2MM_IM_0007_anon.mat\"\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile\\Documents\\MRI-Datasets\\PDFF_Phantom_Data\\datasets\\site6_1p5T_protocol2.mat\"\n",
    "file_dir = \"C:/Users/jpmen/Documents/QSM-Liver/QSM_reconstructions/num_phantom-r2s_060-bg_susc_-15-SNR_100-FF_12.mat\"\n",
    "\n",
    "# Future output variables\n",
    "F = list() # PDFF \n",
    "P = list() # FM \n",
    "R = list() # WF \n",
    "R2= list() # R2 \n",
    "\n",
    "# Future uncertainty variables (AI-DEAL only)\n",
    "PDFF_vars = list()\n",
    "WF_vars = list()\n",
    "R2_vars = list()\n",
    "FM_vars = list()\n",
    "\n",
    "i = 0\n",
    "fm_sc = 300.0\n",
    "r2_sc = 200.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83cedf-42fd-4159-8e46-1e988027c044",
   "metadata": {},
   "source": [
    "In the following block, you can choose the data format to be loaded. The default option is MAT files.\n",
    "\n",
    "It should be noted that the array shape within DICOM files can vary according to the scanner in which MR data was acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dcace14-96e5-496b-b28c-fb3977614d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e36c1f0a4e54f26bb24d4c1c4ca77f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data format:', options=('MAT', 'DICOM', 'QSM'), value='MAT')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sel = widgets.Dropdown(\n",
    "    options=['MAT','DICOM','QSM'],\n",
    "    value='MAT',\n",
    "    description='Data format:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e05b23fc-0f69-4725-876e-6200a630cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_sel.value == 'DICOM':\n",
    "    ds = pydicom.dcmread(py.join(exp_dir,scan_fn))\n",
    "    if X_aux is None:\n",
    "        arr = ds.pixel_array #.transpose()\n",
    "        X_aux = apply_modality_lut(arr, ds).astype(np.float32)\n",
    "        X_aux = np.reshape(X_aux,(1,1,X_aux.shape[0],X_aux.shape[1],1))\n",
    "        TE_aux = np.array([[np.float(ds.EchoTime) * 1e-3]]).astype(np.float32)\n",
    "    else:\n",
    "        arr = ds.pixel_array #.transpose()\n",
    "        X_aux_2 = apply_modality_lut(arr, ds).astype(np.float32)\n",
    "        X_aux_2 = np.reshape(X_aux_2,(1,1,X_aux_2.shape[0],X_aux_2.shape[1],1))\n",
    "        TE_aux_2 = np.array([[np.float(ds.EchoTime) * 1e-3]]).astype(np.float32)\n",
    "        X_aux = np.concatenate((X_aux,X_aux_2), axis=0)\n",
    "        TE_aux = np.concatenate((TE_aux,TE_aux_2), axis=0)\n",
    "elif data_sel.value == 'MAT':\n",
    "    mat = sio.loadmat(file_dir)\n",
    "    if 'imDataParams' in mat.keys():\n",
    "        acq = mat['imDataParams'][0,0][0].astype('complex64')\n",
    "        TE = mat['imDataParams'][0,0][1].astype('float32')\n",
    "    elif 'imDataAll' in  mat.keys():\n",
    "        acq = mat['imDataAll'][0,0][4].astype('complex64')\n",
    "        TE = mat['imDataAll'][0,0][0].astype('float32') #0/2\n",
    "    if acq.shape[0] % 16 != 0.0:\n",
    "        acq = acq[:(acq.shape[0]-acq.shape[0]%16)]\n",
    "    acq = np.transpose(acq, (2,4,0,1,3)) / np.max(np.abs(acq))\n",
    "    acq_real = np.real(acq)\n",
    "    acq_imag = np.imag(acq)\n",
    "    X = np.concatenate((acq_real,acq_imag),axis=-1)\n",
    "    X = np.flip(X,axis=0)\n",
    "elif data_sel.value == 'QSM':\n",
    "    mat = sio.loadmat(file_dir)\n",
    "    acq = mat['S'].astype('complex64')\n",
    "    TE = mat['TE'].astype('float32')\n",
    "    TE *= 1e-3\n",
    "    if acq.shape[0] % 16 != 0.0:\n",
    "        acq = acq[:(acq.shape[0]-acq.shape[0]%16)]\n",
    "    acq = np.transpose(acq, (2,3,0,1))\n",
    "    acq_real = np.real(np.expand_dims(acq,axis=-1))\n",
    "    acq_imag = np.imag(np.expand_dims(acq,axis=-1))\n",
    "    X = np.concatenate((acq_real,acq_imag),axis=-1)\n",
    "    #X = X[::3,...]\n",
    "TE = np.expand_dims(TE,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b019ec41-50b5-4337-b907-c5a03da2569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "TEs = tf.repeat(TE, [X.shape[0]], axis=0)\n",
    "A_dataset = tf.data.Dataset.from_tensor_slices((X,TEs))\n",
    "test_iter = cycle(A_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddba2c12-6588-4310-88f4-d5bd5bd6975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc3a7a-e987-4fb9-a545-f23340c75eb9",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3634df1-edf1-4f7d-bfd3-8d695e9fc536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d936eb0a2b543e4b01ba22ecf591d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Model:', index=4, options=('U-Net', 'MDWF-Net', '2D-Net', 'VET-Net', 'AI-DEAL', 'Single'…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sel = widgets.Dropdown(\n",
    "    options=['U-Net','MDWF-Net','2D-Net','VET-Net','AI-DEAL','Single'],\n",
    "    value='AI-DEAL',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee026ea-3e43-4613-a72c-d9783927b208",
   "metadata": {},
   "source": [
    "The original training dataset had CSE-MRI data from 149 subjects. However, all the models have different versions that were trained using different ratios of real and synthetic data. In the following menu, you can choose the version that you want to use depending on the number of subjects whose (real) data that was used for training.\n",
    "\n",
    "* *Disclaimer:* In the cases of U-Net and MDWF-Net, this option is only valid for 6-echo models; there is only a single 3-echo version for each of them and they were trained using real data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6f820ec-d8a4-47cf-bf88-806ae6a0dcbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df23823acc614c05a107149f9f0ccddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Real subjects considered for training:', index=4, options=(0, 3, 9, 15, 149), value=149)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ratio_sel = widgets.Dropdown(\n",
    "    options=[0,3,9,15,149],\n",
    "    value=149,\n",
    "    description='Real subjects considered for training:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_ratio_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0cc663-a68b-4516-a61c-d32c468e9fcf",
   "metadata": {},
   "source": [
    "Additionally, you can also set the number of echoes to be considered as input. This parameter will change the imported version of U-Net and MDWF-Net models, while the remaining models will not depend on this value as they are able to handle different echo train lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f71a24c-8c95-4dd8-8195-2fe6338efeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ed3bcce6e0458d88de927d57096055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=6, continuous_update=False, description='Num. Echoes:', max=12, min=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ech_sel = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=2,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Num. Echoes:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "ech_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a0d5f-5b97-4a0f-8857-f11c7938ea6f",
   "metadata": {},
   "source": [
    "For those models that use least squares to calculate water-fat signals after demodulating the CSE-MR signal (VET-Net & AI-DEAL), you can also choose to discard the first echo, since it has been demonstrated that its phase is usually corrupted (see [Hernando et al. (2012), *Addressing phase errors in fat‐water imaging using a mixed magnitude/complex fitting method*](https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.23044))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc109ff-ce8a-4952-91dd-4553c29c303e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ddac0d369f46f2b025707481c49846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Remove first echo')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_ech1 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Remove first echo',\n",
    ")\n",
    "remove_ech1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850f23a-416a-4103-ae47-9719fc198c43",
   "metadata": {},
   "source": [
    "Optionally, you can also enable the resoultion of the water-fat separation using a phase-constrained least squares approach. By doing this, you are ensuring that the phase of the water-only and the fat-only signals are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727d5cbd-e621-434d-8bd0-1022f8d58676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82db87406cac4badacd72abc80de9d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Phase-constrained LS')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phase_const = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Phase-constrained LS',\n",
    ")\n",
    "phase_const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7c1e1-d496-4bcd-b8f4-1883ddbcd6d1",
   "metadata": {},
   "source": [
    "Finally, you have to specify the way in which PDFF is going to be calculated:\n",
    "1) Magnitude-based: $$PDFF = \\frac{|\\rho_F|}{|\\rho_W|+|\\rho_F|}$$\n",
    "2) Using magnitude discrimination: $$PDFF = \\begin{cases} \\frac{|\\rho_F|}{|\\rho_W+\\rho_F|} & ,~if~~|\\rho_F|>|\\rho_W| \\\\ 1-\\frac{|\\rho_W|}{|\\rho_W+\\rho_F|} & ,~else \\end{cases}$$\n",
    "\n",
    "If you choose the **phase-constrained solution, both PDFF definitions will be equal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ee3f715-7bfd-4131-9421-d0d46cc3992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca2d43a78984126a0e7141bfa0b1608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='PDFF definition', options=('Magnitude-based', 'Magnitude-discrimination'), value='Magnit…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdff_def = widgets.Dropdown(\n",
    "    options=['Magnitude-based','Magnitude-discrimination'],\n",
    "    value='Magnitude-based',\n",
    "    description='PDFF definition',\n",
    "    disabled=False,\n",
    ")\n",
    "pdff_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378e143-b76b-47e7-933d-d9d5b70debbb",
   "metadata": {},
   "source": [
    "_Experimental:_ There is an ongoing development of a VET-Net model for 3T CSE-MRI. You can enable the 3T model by clicking the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b724f791-9851-4634-86e4-4ff6dd4bf47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956a34826ad74f6091d5cbce77db514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='3T Model')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enable_3p0 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='3T Model',\n",
    ")\n",
    "enable_3p0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdd7fa-8a74-4a4c-8148-1d6fd6f9025d",
   "metadata": {},
   "source": [
    "## Building the model's architecture and loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2088ea10-61e0-4921-8c8c-eb57b40d987d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_sel.value == 'U-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-202'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-403'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-402'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-401'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-400'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-203'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,2*ech_sel.value), n_out=2, filters=args.n_G_filters,output_activation='relu')\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'MDWF-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-204'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-404'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-405'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-406'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-407'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-205'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.MDWF_Generator(input_shape=(None,None,2*ech_sel.value), filters=args.n_G_filters, \n",
    "                              WF_self_attention=args.D1_SelfAttention, R2_self_attention=args.D2_SelfAttention,\n",
    "                              FM_self_attention=args.D3_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == '2D-Net':\n",
    "    model_fn = 'Sup-200'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.PM_Generator(input_shape=(None,None,2*ech_sel.value), te_input=False, ME_layer=None, filters=args.n_G_filters)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'VET-Net':\n",
    "    if enable_3p0.value:\n",
    "        model_fn = 'TEaug-301'\n",
    "    else:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'TEaug-300'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'TEaug-311'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'TEaug-310'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'TEaug-309'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'TEaug-308'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.PM_Generator(input_shape=(None,None,None,2), te_input=True, te_shape=(None,), filters=args.n_G_filters)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'AI-DEAL':\n",
    "    experiment_dir = py.join('output','Unsup-306')\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,None,2), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    self_attention=args.D1_SelfAttention)\n",
    "    G_A2R2= dl.UNet(input_shape=(None,None,None,1), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    output_activation='sigmoid', self_attention=args.D2_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B, G_A2R2=G_A2R2), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'Single':\n",
    "    experiment_dir = py.join('output','Single-224')\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_mag = dl.UNet(input_shape=(None,None,None,1),n_out=3,ME_layer=True,filters=args.n_G_filters,\n",
    "                output_activation='sigmoid',self_attention=args.D1_SelfAttention)\n",
    "    G_pha = dl.UNet(input_shape=(None,None,None,1),n_out=4,ME_layer=True,filters=args.n_G_filters,\n",
    "                    output_activation='linear',self_attention=args.D2_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_mag=G_mag, G_pha=G_pha), py.join(experiment_dir, 'checkpoints'))\n",
    "\n",
    "try:  # restore checkpoint including the epoch counter\n",
    "    checkpoint.restore().assert_existing_objects_matched()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc3edd-57a9-4b5d-9e17-9f0a48f6b1ac",
   "metadata": {},
   "source": [
    "## Preparing the PDFF estimation workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a71ce21f-c096-4589-9f4e-c3b13e16e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function\n",
    "@tf.function\n",
    "def sample(A, TE):\n",
    "    A_abs = tf.math.sqrt(tf.reduce_sum(tf.square(A), axis=-1, keepdims=True))\n",
    "    A_msk = tf.reduce_mean(A_abs, axis=1, keepdims=True)\n",
    "    A2B_msk = tf.concat([A_msk,A_msk], axis=-1)\n",
    "    if A.shape[1] > ech_sel.value:\n",
    "        A = A[:,:ech_sel.value,...]\n",
    "        TE = TE[:,:ech_sel.value,...]\n",
    "    if model_sel.value == 'U-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B_WF_abs = G_A2B(A_pf, training=False)\n",
    "        A2B_WF_abs = tf.expand_dims(A2B_WF_abs, axis=1)\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, tf.zeros_like(A2B_WF[:,:1,...])], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'MDWF-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B = G_A2B(A_pf, training=False)\n",
    "        A2B = tf.expand_dims(A2B, axis=1)\n",
    "        A2B_PM = A2B[...,-1:-3:-1]\n",
    "        A2B_WF_abs = A2B[...,:2]\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == '2D-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B_PM = G_A2B(A_pf, training=False)\n",
    "        A2B_PM = tf.expand_dims(A2B_PM, axis=1)\n",
    "        A2B_PM = A2B_PM[...,::-1]\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF = wf.get_rho(A[:,1:,...], A2B_PM, te=TE[:,1:,...])\n",
    "        else:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, te=TE, phase_constraint=phase_const.value)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'VET-Net':\n",
    "        A2B_PM = G_A2B([A,TE], training=False) #[:,:ech_sel.value,...]\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF = wf.get_rho(A[:,1:,...], A2B_PM, te=TE[:,1:,...])\n",
    "        else:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, te=TE, phase_constraint=phase_const.value)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'AI-DEAL':\n",
    "        A2B_var_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        A2B_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_FM = G_A2B(A[:,1:,...], training=False)\n",
    "        else:\n",
    "            A2B_FM = G_A2B(A, training=False)\n",
    "        A2B_R2 = G_A2R2(A_abs, training=False)\n",
    "        A2B_PM = tf.concat([A2B_FM.mean(),A2B_R2.mean()],axis=-1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A[:,1:,...], A2B_FM, A2B_R2, te=TE[:,1:,...], rem_R2=False)\n",
    "        else:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A, A2B_FM, A2B_R2, te=TE, rem_R2=False)\n",
    "        A2B_WF_var = tf.concat([A2B_WF_var,tf.zeros_like(A2B_WF_var)],axis=-1)\n",
    "        A2B_PM_var = tf.concat([A2B_FM.variance(),A2B_R2.variance()],axis=-1)\n",
    "        A2B_var = tf.concat([A2B_WF_var,A2B_PM_var], axis=1)\n",
    "        A2B_var = tf.where(A2B_var_msk>=5e-2, A2B_var, 0.0)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "    elif model_sel.value == 'Single':\n",
    "        A_pha = tf.math.atan2(A[...,1:],A[...,:1]) / np.pi\n",
    "        A2B_abs = G_mag(A_abs, training=False)\n",
    "        A2B_pha = G_pha(A_pha, training=False)\n",
    "        A2B_WF_abs = A2B_abs[...,:2]\n",
    "        A2B_WF_pha = A2B_pha[...,:2]\n",
    "        A2B_WF_r = A2B_WF_abs * tf.math.cos(4*np.pi*A2B_WF_pha)\n",
    "        A2B_WF_i = A2B_WF_abs * tf.math.sin(4*np.pi*A2B_WF_pha)\n",
    "        A2B_WF = tf.concat([A2B_WF_r,A2B_WF_i],axis=1)\n",
    "        A2B_WF = tf.transpose(A2B_WF,perm=[0,4,2,3,1])\n",
    "        A2B_PM = tf.concat([A2B_pha[...,2:3],A2B_abs[...,2:]],axis=-1)\n",
    "        A2B_bip = tf.concat([A2B_pha[...,-1:],tf.zeros_like(A2B_pha[...,-1:])],axis=-1)\n",
    "        A2B = tf.concat([A2B_WF,A2B_PM,A2B_bip],axis=1)\n",
    "        A2B_bip_msk = tf.repeat(A_msk,4,axis=1)\n",
    "        A2B = tf.where(A2B_bip_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    return A2B, A2B_var\n",
    "\n",
    "def test(A, TE=None):\n",
    "    A2B, A2B_var = sample(A, TE)\n",
    "    return A2B, A2B_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bc697-6c87-44c6-8728-4364ee92c206",
   "metadata": {},
   "source": [
    "## Slice-by-slice loading and testing\n",
    "Each time that you run the following cell, you will be moving one slide down. The next cells will execute the water-fat separation and PDFF quantification for the chosen slice. Please first choose the number of slices that you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02f343e5-ff93-4cf6-9709-ed3351cb3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0e3cb8dfbc404893c3ef50f5adb070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=1, continuous_update=False, description='Num. slices:', max=80, min=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_slices = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=X.shape[0],\n",
    "    step=1,\n",
    "    description='Num. slices:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "run_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f0c9559-84b7-433a-8b90-42a83294c0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpmen\\AppData\\Local\\Temp\\ipykernel_33352\\512729417.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "  PDFF_aux = f_m_aux/(w_m_aux+f_m_aux)\n",
      "C:\\Users\\jpmen\\AppData\\Local\\Temp\\ipykernel_33352\\512729417.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  PDFF_var = Aux_WF_var/(Aux_WF**2)\n",
      "C:\\Users\\jpmen\\AppData\\Local\\Temp\\ipykernel_33352\\512729417.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  PDFF_var -= 2 * WF_var / (Aux_WF*wf_m_aux)\n",
      "C:\\Users\\jpmen\\AppData\\Local\\Temp\\ipykernel_33352\\512729417.py:47: RuntimeWarning: invalid value encountered in divide\n",
      "  PDFF_var += (W_var + F_var + 2*WF_var)/(wf_m_aux)\n",
      "C:\\Users\\jpmen\\AppData\\Local\\Temp\\ipykernel_33352\\512729417.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  PDFF_var *= Aux_WF**2 / (wf_m_aux)**2 #[W_var,WF_var,F_var]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(run_slices.value):\n",
    "    A, TE = next(test_iter)\n",
    "    A = tf.expand_dims(A,axis=0)\n",
    "    TE = tf.expand_dims(TE,axis=0)\n",
    "    A2B, A2B_var = test(A, TE)\n",
    "    i+=1\n",
    "    \n",
    "    # CSE-MR images at each echo\n",
    "    mag_ech1 = np.squeeze(np.abs(tf.complex(A[:,0,:,:,0],A[:,0,:,:,1])))\n",
    "    pha_ech1 = np.squeeze(np.arctan2(A[:,0,:,:,1],A[:,0,:,:,0]))\n",
    "    mag_ech2 = np.squeeze(np.abs(tf.complex(A[:,1,:,:,0],A[:,1,:,:,1])))\n",
    "    pha_ech2 = np.squeeze(np.arctan2(A[:,1,:,:,1],A[:,1,:,:,0]))\n",
    "    mag_ech3 = np.squeeze(np.abs(tf.complex(A[:,2,:,:,0],A[:,2,:,:,1])))\n",
    "    pha_ech3 = np.squeeze(np.arctan2(A[:,2,:,:,1],A[:,2,:,:,0]))\n",
    "    \n",
    "    # Estimated quantitative maps\n",
    "    w_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1],A2B[:,0,:,:,1:])),axis=0)\n",
    "    w_p_aux = np.squeeze(tf.math.atan2(A2B[:,0,:,:,1],A2B[:,0,:,:,0]))\n",
    "    f_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,1,:,:,:1],A2B[:,1,:,:,1:])),axis=0)\n",
    "    f_p_aux = np.squeeze(tf.math.atan2(A2B[:,1,:,:,1],A2B[:,1,:,:,0]))\n",
    "    wf_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1]+A2B[:,1,:,:,:1],A2B[:,0,:,:,1:]+A2B[:,1,:,:,1:])),axis=0)\n",
    "    r2_aux = np.squeeze(A2B[:,2,:,:,1])\n",
    "    field_aux = np.squeeze(A2B[:,2,:,:,0])\n",
    "    if pdff_def.value == 'Magnitude-based':\n",
    "        PDFF_aux = f_m_aux/(w_m_aux+f_m_aux)\n",
    "    elif pdff_def.value == 'Magnitude-discrimination':\n",
    "        PDFF_aux = np.where(f_m_aux >= w_m_aux, f_m_aux/wf_m_aux, 1-(w_m_aux/wf_m_aux))\n",
    "    PDFF_aux[np.isnan(PDFF_aux)] = 0.0\n",
    "    # Update maps to be saved in MAT file\n",
    "    F.append(PDFF_aux*100.0)\n",
    "    P.append(np.expand_dims(field_aux*fm_sc, axis=-1))\n",
    "    R.append(np.expand_dims(np.concatenate([w_m_aux,f_m_aux],axis=-1), axis=-2))\n",
    "    R2.append(np.expand_dims(r2_aux*r2_sc, axis=-1))\n",
    "    \n",
    "    # Estimated uncertainty maps (if available)\n",
    "    if A2B_var is not None:\n",
    "        W_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,0,:,:,:1],A2B_var[:,0,:,:,1:])),axis=0)\n",
    "        WF_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,1,:,:,:1],A2B_var[:,1,:,:,1:])),axis=0)\n",
    "        F_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,3,:,:,:1],A2B_var[:,3,:,:,1:])),axis=0)\n",
    "        r2s_var = np.squeeze(A2B_var[:,-1,:,:,1:],axis=0)*(r2_sc**2)\n",
    "        field_var = np.squeeze(A2B_var[:,-1,:,:,:1],axis=0)*(fm_sc**2)\n",
    "    \n",
    "        Aux_WF = np.where(f_m_aux>=w_m_aux, f_m_aux, w_m_aux)\n",
    "        Aux_WF_var = np.where(f_m_aux>=w_m_aux, F_var, W_var)\n",
    "        PDFF_var = Aux_WF_var/(Aux_WF**2)\n",
    "        PDFF_var -= 2 * WF_var / (Aux_WF*wf_m_aux)\n",
    "        PDFF_var += (W_var + F_var + 2*WF_var)/(wf_m_aux)\n",
    "        PDFF_var *= Aux_WF**2 / (wf_m_aux)**2 #[W_var,WF_var,F_var]\n",
    "        PDFF_var = np.nan_to_num(PDFF_var)\n",
    "        \n",
    "        # Update maps to be saved in MAT file\n",
    "        PDFF_vars.append(PDFF_var*1e4)\n",
    "        WF_vars.append(np.expand_dims(np.concatenate([W_var,WF_var,F_var],axis=-1), axis=-2))\n",
    "        R2_vars.append(r2s_var)\n",
    "        FM_vars.append(field_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab56ee-4bf1-44cd-b894-6298daea4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16, 4), nrows=2, ncols=6)\n",
    "\n",
    "# Acquisitions in the first row\n",
    "acq_ech1 = axs[0,0].imshow(mag_ech1, cmap='gray',\n",
    "                      interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,0].set_title('Mag 1st Echo')\n",
    "axs[0,0].axis('off')\n",
    "acq_ech2 = axs[0,1].imshow(pha_ech1/np.pi, cmap='gist_earth',\n",
    "                      interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,1].set_title('Phase 1st Echo')\n",
    "axs[0,1].axis('off')\n",
    "acq_ech3 = axs[0,2].imshow(mag_ech2, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,2].set_title('Mag 2nd Echo')\n",
    "axs[0,2].axis('off')\n",
    "acq_ech4 = axs[0,3].imshow(pha_ech2/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,3].set_title('Phase 2nd Echo')\n",
    "axs[0,3].axis('off')\n",
    "acq_ech5 = axs[0,4].imshow(mag_ech3, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,4].set_title('Mag 3rd Echo')\n",
    "axs[0,4].axis('off')\n",
    "acq_ech6 = axs[0,5].imshow(pha_ech3/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,5].set_title('Phase 3rd Echo')\n",
    "axs[0,5].axis('off')\n",
    "\n",
    "# A2B maps in the second row\n",
    "W_ok =  axs[1,0].imshow(w_m_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "\n",
    "Wp_ok =  axs[1,1].imshow(w_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Wp_ok, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "F_ok =  axs[1,2].imshow(f_m_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=axs[1,2])\n",
    "axs[1,2].axis('off')\n",
    "\n",
    "Fp_ok =  axs[1,3].imshow(f_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Fp_ok, ax=axs[1,3])\n",
    "axs[1,3].axis('off')\n",
    "\n",
    "r2_ok = axs[1,4].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[1,4])\n",
    "axs[1,4].axis('off')\n",
    "\n",
    "field_ok =  axs[1,5].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=axs[1,5])\n",
    "axs[1,5].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.8)\n",
    "fig.set_facecolor(\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cf2a4-b2f1-458a-9a48-0625ed48c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if A2B_var is not None:\n",
    "    from matplotlib.colors import LogNorm\n",
    "    fig, axs = plt.subplots(figsize=(15, 4), nrows=2, ncols=5)\n",
    "\n",
    "    # Estimated maps\n",
    "    FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "    axs[0,0].axis('off')\n",
    "    W_ok =  axs[0,1].imshow(w_m_aux, cmap='bone',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(W_ok, ax=axs[0,1])\n",
    "    axs[0,1].axis('off')\n",
    "\n",
    "    F_ok =  axs[0,2].imshow(f_m_aux, cmap='pink',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(F_ok, ax=axs[0,2])\n",
    "    axs[0,2].axis('off')\n",
    "\n",
    "    r2_ok = axs[0,3].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                            interpolation='none', vmin=0, vmax=r2_sc)\n",
    "    fig.colorbar(r2_ok, ax=axs[0,3])\n",
    "    axs[0,3].axis('off')\n",
    "\n",
    "    field_ok =  axs[0,4].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                                interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "    fig.colorbar(field_ok, ax=axs[0,4])\n",
    "    axs[0,4].axis('off')\n",
    "    \n",
    "    WF_uq = axs[1,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "    fig.colorbar(WF_uq, ax=axs[1,0])\n",
    "    axs[1,0].axis('off')\n",
    "\n",
    "    W_uq = axs[1,1].matshow(W_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "    fig.colorbar(W_uq, ax=axs[1,1])\n",
    "    axs[1,1].axis('off')\n",
    "\n",
    "    F_uq = axs[1,2].matshow(F_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "    fig.colorbar(F_uq, ax=axs[1,2])\n",
    "    axs[1,2].axis('off')\n",
    "\n",
    "    r2s_uq=axs[1,3].matshow(r2s_var, cmap='gnuplot',\n",
    "                          norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "    fig.colorbar(r2s_uq, ax=axs[1,3])\n",
    "    axs[1,3].axis('off')\n",
    "\n",
    "    field_uq = axs[1,4].matshow(field_var, cmap='gnuplot2',\n",
    "                                norm=LogNorm(vmin=1e-5,vmax=1e-2))\n",
    "    fig.colorbar(field_uq, ax=axs[1,4])\n",
    "    axs[1,4].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bb1e3-6882-4e3c-afef-350fa851d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "# plt.matshow(PDFF_aux*100.0,cmap='jet',vmin=0.0,vmax=100.0, fignum=1)\n",
    "plt.matshow(PDFF_var*1e4, cmap='gnuplot2',vmin=0,vmax=1e2, fignum=1)\n",
    "# plt.matshow(r2_aux*r2_sc, cmap='copper', vmin=0, vmax=r2_sc, fignum=1)\n",
    "# plt.matshow(r2s_var, cmap='gnuplot', vmin=0,vmax=1e2, fignum=1)\n",
    "# plt.matshow(w_m_aux, cmap='bone', vmin=0, vmax=1, fignum=1)\n",
    "# plt.matshow(f_m_aux, cmap='pink', vmin=0, vmax=1, fignum=1)\n",
    "# plt.matshow(F_var, cmap='gnuplot2', norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "# plt.matshow(field_aux*fm_sc,cmap='twilight',fignum=1)\n",
    "# plt.matshow(A2B[0,3,:,:,0],cmap='twilight',vmin=-.5,vmax=.5,fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34e6f5-ef76-4f44-abaa-9645577ab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_pha = tf.math.atan2(A[...,1:],A[...,:1]) / np.pi\n",
    "# A_pha = np.angle(acq[:1,...]) \n",
    "# A2B_pha = G_pha(A_pha, training=False)\n",
    "\n",
    "x = tf.linspace(-.5,.5,A.shape[2])\n",
    "X, Y = tf.meshgrid(x, x)\n",
    "B_bp = tf.roll(X,shift=A.shape[2]//2,axis=1) #tf.where(field_aux!=0.0,X,0.0)\n",
    "\n",
    "# B_diff = B_bp[:,96:192] + B_bp[:,-97:-(192+1):-1] # left half\n",
    "# B_diff = B_bp[:,-97:-192:-1] # right half\n",
    "\n",
    "B_bp_tf = tf.expand_dims(B_bp,axis=0)\n",
    "B_bp_tf = tf.expand_dims(B_bp_tf,axis=-1)\n",
    "BP_dy, BP_dx = tf.image.image_gradients(B_bp_tf)\n",
    "\n",
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "plt.matshow(np.squeeze(BP_dx))#,cmap='twilight',vmin=-1,vmax=1,fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab33ad-1d8d-4808-b00b-4f881c7ad354",
   "metadata": {},
   "source": [
    "## Export results to a MAT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9ac4aa5-4df8-4440-9870-6d252d3c6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_sel.value == 'QSM':\n",
    "    out_id = file_dir.split('/')[-1].split('.')[0]\n",
    "else:\n",
    "    out_id = file_dir.split('/')[-2].split('_')[-1]\n",
    "listdir = file_dir.split('/')[:-1]\n",
    "listdir.append('res_MP_' + ''.join(model_sel.value.split('-')) + '_' + out_id + '.mat')\n",
    "outpath = '/'.join(listdir)\n",
    "\n",
    "outvars = {'F': np.concatenate(F,axis=-1),\n",
    "           'P': np.concatenate(P,axis=-1),\n",
    "           'R': np.concatenate(R,axis=-2),\n",
    "           'R2':np.concatenate(R2,axis=-1),\n",
    "           'mthd': model_sel.value}\n",
    "\n",
    "if A2B_var is not None:\n",
    "    var_outvars = {'F_var': np.concatenate(PDFF_vars, axis=-1),\n",
    "                   'R_var': np.concatenate(WF_vars, axis=-2),\n",
    "                   'R2_var': np.concatenate(R2_vars, axis=-1),\n",
    "                   'P_var': np.concatenate(FM_vars, axis=-1)}\n",
    "    outvars.update(var_outvars)\n",
    "\n",
    "sio.savemat(outpath, outvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b68734-c333-4029-afc8-c9eec9b85359",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optional: Load reference results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe6362-e07c-4398-aa26-b590dd3f5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_JGalgani/004/results_MP_GC/IM_0007_anon_MP_GC.mat\"\n",
    "out_file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/multi-echo/02752/CIB_JAVIER_SILVA/Bipolar-12ech/results_MP_GC_IM_0045/2D_NSA4_12TE_FB_NO_dTE_11_MP_GC.mat\"\n",
    "mat = sio.loadmat(out_file_dir)\n",
    "B_WF = np.flip(mat['R'].astype('complex64'),axis=-2)\n",
    "B_WF = B_WF / np.max(np.abs(np.sum(B_WF,axis=-1,keepdims=True)))\n",
    "B_R2 = np.flip(mat['R2'].astype('float32'),axis=-1)\n",
    "B_FM = np.flip(mat['P'].astype('float32'),axis=-1)\n",
    "B_PDFF = np.flip(mat['F'].astype('float32'),axis=-1)\n",
    "\n",
    "A_msk = np.abs(np.sum(B_WF,axis=-1,keepdims=False))>=5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c43d7e-1712-4f8e-a4e6-31919c450a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_W = np.expand_dims(mat['fwmc_w'].astype('float32'),axis=-1)\n",
    "B_F = np.expand_dims(mat['fwmc_f'].astype('float32'),axis=-1)\n",
    "B_WF = np.concatenate((B_W,B_F),axis=-1)\n",
    "B_WF = B_WF / np.max(np.abs(np.sum(B_WF,axis=-1,keepdims=True)))\n",
    "B_R2 = np.flip(mat['fwmc_r2star'].astype('float32'),axis=-1)\n",
    "B_FM = np.zeros_like(B_R2)\n",
    "B_PDFF = np.flip(mat['fwmc_ff'].astype('float32'),axis=-1)\n",
    "\n",
    "if B_W.shape[0] % 16 != 0.0:\n",
    "    B_W = B_W[:(B_W.shape[0]-B_W.shape[0]%16)]\n",
    "    B_F = B_F[:(B_F.shape[0]-B_F.shape[0]%16)]\n",
    "    B_WF= B_WF[:(B_WF.shape[0]-B_WF.shape[0]%16)]\n",
    "    B_R2= B_R2[:(B_R2.shape[0]-B_R2.shape[0]%16)]\n",
    "    B_FM = B_FM[:(B_FM.shape[0]-B_FM.shape[0]%16)]\n",
    "    B_PDFF= B_PDFF[:(B_PDFF.shape[0]-B_PDFF.shape[0]%16)]\n",
    "\n",
    "A_msk = np.abs(np.sum(B_WF,axis=-1,keepdims=False))>=50e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef4b7f-0a62-48f9-859a-ba7c16491db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_PDFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddf07f-4b86-4d0b-8842-b6a5f4752b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_aux = np.abs(B_WF[...,i-1:i,0]) *  A_msk[...,i-1:i] \n",
    "fn_aux = np.abs(B_WF[...,i-1:i,1]) *  A_msk[...,i-1:i] \n",
    "r2n_aux = np.squeeze(B_R2[...,i-1:i]) * A_msk[...,i-1]\n",
    "fieldn_aux = np.squeeze(B_FM[...,i-1:i]) * A_msk[...,i-1]\n",
    "PDFFn_aux = B_PDFF[...,i-1:i]/100.0 * A_msk[...,i-1:i]\n",
    "PDFF_aux = PDFF_aux * A_msk[...,i-1:i]\n",
    "\n",
    "fig,axs=plt.subplots(figsize=(12.7, 8), nrows=4, ncols=5)\n",
    "\n",
    "# Estimated maps in the first row\n",
    "FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "axs[0,0].axis('off')\n",
    "W_ok =  axs[0,1].imshow(w_m_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=axs[0,1])\n",
    "axs[0,1].axis('off')\n",
    "F_ok =  axs[0,2].imshow(f_m_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=axs[0,2])\n",
    "axs[0,2].axis('off')\n",
    "r2_ok = axs[0,3].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[0,3])\n",
    "axs[0,3].axis('off')\n",
    "field_ok =  axs[0,4].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=axs[0,4])\n",
    "axs[0,4].axis('off')\n",
    "\n",
    "# Ground-truth maps in the second row\n",
    "FF_gt = axs[1,0].imshow(PDFFn_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_gt, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "W_gt =  axs[1,1].imshow(wn_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_gt, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "F_gt =  axs[1,2].imshow(fn_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_gt, ax=axs[1,2])\n",
    "axs[1,2].axis('off')\n",
    "r2_gt = axs[1,3].imshow(r2n_aux, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_gt, ax=axs[1,3])\n",
    "axs[1,3].axis('off')\n",
    "field_gt =  axs[1,4].imshow(fieldn_aux, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_gt, ax=axs[1,4])\n",
    "axs[1,4].axis('off')\n",
    "\n",
    "# Error w.r.t. reference in the third row\n",
    "FF_est =axs[2,0].imshow(np.abs(PDFF_aux-PDFFn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(FF_est, ax=axs[2,0])\n",
    "axs[2,0].axis('off')\n",
    "W_est = axs[2,1].imshow(np.abs(w_m_aux-wn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(W_est, ax=axs[2,1])\n",
    "axs[2,1].axis('off')\n",
    "\n",
    "F_est = axs[2,2].imshow(np.abs(f_m_aux-fn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(F_est, ax=axs[2,2])\n",
    "axs[2,2].axis('off')\n",
    "\n",
    "r2_est= axs[2,3].imshow(np.abs(r2_aux*r2_sc-r2n_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(r2_est, ax=axs[2,3])\n",
    "axs[2,3].axis('off')\n",
    "\n",
    "field_est = axs[2,4].imshow(np.abs(field_aux*fm_sc-fieldn_aux), cmap='gray',\n",
    "                            interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(field_est, ax=axs[2,4])\n",
    "axs[2,4].axis('off')\n",
    "\n",
    "# Uncertainty maps in the fourth row\n",
    "WF_uq = axs[3,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                         norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "fig.colorbar(WF_uq, ax=axs[3,0])\n",
    "axs[3,0].axis('off')\n",
    "W_uq = axs[3,1].matshow(W_var, cmap='gnuplot2',\n",
    "                        norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "fig.colorbar(W_uq, ax=axs[3,1])\n",
    "axs[3,1].axis('off')\n",
    "F_uq = axs[3,2].matshow(F_var, cmap='gnuplot2',\n",
    "                        norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "fig.colorbar(F_uq, ax=axs[3,2])\n",
    "axs[3,2].axis('off')\n",
    "r2s_uq=axs[3,3].matshow(r2s_var, cmap='gnuplot',\n",
    "                        norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "fig.colorbar(r2s_uq, ax=axs[3,3])\n",
    "axs[3,3].axis('off')\n",
    "field_uq = axs[3,4].matshow(field_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-5,vmax=1e-2))\n",
    "fig.colorbar(field_uq, ax=axs[3,4])\n",
    "axs[3,4].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2071f-303e-4d16-baae-3eb0a1c41d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(figsize=(5, 8), nrows=4, ncols=2)\n",
    "\n",
    "# Estimated maps in the first row\n",
    "FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "axs[0,0].axis('off')\n",
    "r2_ok = axs[0,1].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[0,1])\n",
    "axs[0,1].axis('off')\n",
    "\n",
    "# Ground-truth maps in the second row\n",
    "FF_gt = axs[1,0].imshow(PDFFn_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_gt, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "r2_gt = axs[1,1].imshow(r2n_aux, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_gt, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "# Error w.r.t. reference in the third row\n",
    "FF_est =axs[2,0].imshow(np.abs(PDFF_aux-PDFFn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(FF_est, ax=axs[2,0])\n",
    "axs[2,0].axis('off')\n",
    "r2_est= axs[2,1].imshow(np.abs(r2_aux*r2_sc-r2n_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(r2_est, ax=axs[2,1])\n",
    "axs[2,1].axis('off')\n",
    "\n",
    "# Uncertainty maps in the fourth row\n",
    "WF_uq = axs[3,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                         norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "fig.colorbar(WF_uq, ax=axs[3,0])\n",
    "axs[3,0].axis('off')\n",
    "r2s_uq=axs[3,1].matshow(r2s_var, cmap='gnuplot',\n",
    "                        norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "fig.colorbar(r2s_uq, ax=axs[3,1])\n",
    "axs[3,1].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5e44a-28ad-473c-a9e1-39c63451f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "# plt.matshow(PDFFn_aux*100.0,cmap='jet',vmin=0.0,vmax=100.0, fignum=1)\n",
    "plt.matshow(np.abs(PDFF_aux-PDFFn_aux)*100.0, cmap='gray', vmin=0, vmax=20, fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
