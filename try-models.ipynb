{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef027949-c23c-4e44-8696-59933df1b9fd",
   "metadata": {},
   "source": [
    "# Trying Deep Learning models for MRI-based Water-fat separation\n",
    "In this notebook, you can upload your own Chemical Shift-Encoded (CSE)-MR images and obtain the separated water-fat signals using the different DL-based models developed in this project. All of them were developed to work only with CSE-MR images obtained at **1.5T** scanners.\n",
    "\n",
    "The accepted data formats to upload your data are:\n",
    "* DICOM files\n",
    "* MAT files - using the [ISMRM Water-Fat Toolbox](https://www.ismrm.org/workshops/FatWater12/data.htm) format\n",
    "\n",
    "The available DL models for testing are:\n",
    "* U-Net\n",
    "* Multi-Decoder Water-Fat separation Network (MDWF-Net) - Refer to [DOI:10.1007/s00330-023-09576-2](https://doi.org/10.1007/s00330-023-09576-2)\n",
    "* Variable Echo Times neural Network (VET-Net) - Refer to [DOI:10.1007/s00330-024-11164-x](https://doi.org/10.1007/s00330-024-11164-x)\n",
    "* Artificial Intelligence-based Decomposition of water and fat with Echo asymmetry and Least squares estimation (AI-DEAL) - Soon to be published!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c47bb-db5c-4d36-be92-47969ae04fd0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e60782-ce5e-4df2-b7d0-060e95c4bce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from itertools import cycle\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74bc1f-eba0-4130-927c-733e63438753",
   "metadata": {},
   "source": [
    "Optionally, you can disable any available GPU. This is useful if your GPU's size is not enough to handle the data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c4a31-3ac5-4e17-bc39-5dcfe7ea2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a0c3a-44f3-4c9c-888e-0b64dc14f76a",
   "metadata": {},
   "source": [
    "Finally, we the customized libraries included in this repository are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6532dd9-fd8b-48bd-b41b-8b5cbd4b2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2lib as tl\n",
    "import DLlib as dl\n",
    "import pylib as py\n",
    "import wflib as wf\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced9452-f60b-4ce1-b034-b7f40fa3af1b",
   "metadata": {},
   "source": [
    "## Loading CSE-MRI data\n",
    "First, the dataset directory must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72642abc-c28e-449f-a89b-2fcffbb27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory - Read DICOM files\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_INTA/016/2D_NSA1_24S_2MM_IM_0007_anon/2D_NSA1_24S_2MM_IM_0007_anon.mat\"\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile\\Documents\\MRI-Datasets\\PDFF_Phantom_Data\\datasets\\site5_1p5T_protocol1.mat\"\n",
    "file_dir = \"C:/Users/jpmen/Documents/AI-PDFF/data/BVH001/MR_20180404/MECSE_301_MECSE/\"\n",
    "\n",
    "# Future output variables\n",
    "F = list() # PDFF \n",
    "P = list() # FM \n",
    "R = list() # WF \n",
    "R2= list() # R2 \n",
    "\n",
    "# Future uncertainty variables (AI-DEAL only)\n",
    "PDFF_vars = list()\n",
    "WF_vars = list()\n",
    "R2_vars = list()\n",
    "FM_vars = list()\n",
    "\n",
    "i = 0\n",
    "fm_sc = 300.0\n",
    "r2_sc = 200.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83cedf-42fd-4159-8e46-1e988027c044",
   "metadata": {},
   "source": [
    "In the following block, you can choose the data format to be loaded. The default option is MAT files.\n",
    "\n",
    "It should be noted that the array shape within DICOM files can vary according to the scanner in which MR data was acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcace14-96e5-496b-b28c-fb3977614d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02901f49173414591d411061fc4b36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Data format:', options=('MAT', 'DICOM', 'NIFTI', 'QSM'), value='MAT')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sel = widgets.Dropdown(\n",
    "    options=['MAT','DICOM','NIFTI','QSM'],\n",
    "    value='MAT',\n",
    "    description='Data format:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50bd6763-c54d-43a5-81d3-c84fd6089f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_files = sorted([os.path.join(file_dir, f) for f in os.listdir(file_dir)\n",
    "                          if f.endswith(\".dcm\")])\n",
    "for j, f in enumerate(dicom_files[:100]):\n",
    "    # f = dicom_files[0]\n",
    "    ds = pydicom.dcmread(f)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    img_comp = str(ds.get((0x2005, 0x1011), pydicom.DataElement((0x2005, 0x1011), 'DS', 1)).value)\n",
    "    echo_time = float(ds.get((0x0018, 0x0081), pydicom.DataElement((0x0018, 0x0081), 'DS', 1)).value)\n",
    "    echo_num = int(ds.get((0x0018, 0x0086), pydicom.DataElement((0x0018, 0x0086), 'DS', 1)).value)\n",
    "    echo_all = int(ds.get((0x0018, 0x0091), pydicom.DataElement((0x0018, 0x0091), 'DS', 1)).value)\n",
    "    # print(echo_all,img.shape[0],img.shape[1],2)\n",
    "    print(img_comp,echo_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e05b23fc-0f69-4725-876e-6200a630cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_sel.value == 'DICOM':\n",
    "    # images = []\n",
    "    # te_list = []\n",
    "    err_flag = False\n",
    "    dicom_files = sorted([os.path.join(file_dir, f) for f in os.listdir(file_dir)\n",
    "                          if f.endswith(\".dcm\")])\n",
    "    f = dicom_files[0]\n",
    "    ds = pydicom.dcmread(f)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    echo_all = int(ds.get((0x0018, 0x0091), pydicom.DataElement((0x0018, 0x0091), 'DS', 1)).value)\n",
    "    X = np.ones((40,echo_all,img.shape[0],img.shape[1],1),dtype=np.complex64)\n",
    "    TE = np.zeros((40,echo_all),dtype=np.float32)\n",
    "    n_sl = 0\n",
    "    \n",
    "    for j, f in enumerate(dicom_files):\n",
    "        ds = pydicom.dcmread(f)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "\n",
    "        img_comp = str(ds.get((0x2005, 0x1011), pydicom.DataElement((0x2005, 0x1011), 'DS', 1)).value)\n",
    "        echo_time = float(ds.get((0x0018, 0x0081), pydicom.DataElement((0x0018, 0x0081), 'DS', 1)).value)\n",
    "        echo_num = int(ds.get((0x0018, 0x0086), pydicom.DataElement((0x0018, 0x0086), 'DS', 1)).value)\n",
    "        echo_all = int(ds.get((0x0018, 0x0091), pydicom.DataElement((0x0018, 0x0091), 'DS', 1)).value)\n",
    "        RescaleIntercept = float(ds.get((0x2005, 0x100D), pydicom.DataElement((0x2005, 0x100D), 'DS', 1)).value)\n",
    "        RescaleSlope = float(ds.get((0x2005, 0x100E), pydicom.DataElement((0x2005, 0x100E), 'DS', 1)).value)\n",
    "\n",
    "        resc_img = (img-RescaleIntercept)/RescaleSlope\n",
    "\n",
    "        if img_comp == \"M\":\n",
    "            X[n_sl,echo_num-1,:,:,0] *= resc_img\n",
    "        elif img_comp == \"P\":\n",
    "            X[n_sl,echo_num-1,:,:,0] *= np.exp(1j*resc_img)\n",
    "            TE[n_sl,echo_num-1] = echo_time\n",
    "            if echo_num == echo_all:\n",
    "                n_sl += 1\n",
    "    \n",
    "    X = X[:n_sl,...]\n",
    "    TE = TE[:n_sl,...]\n",
    "\n",
    "    rem_sl = []\n",
    "    for sl in range(X.shape[0]):\n",
    "        for ech in range(X.shape[1]):\n",
    "            if (abs(X[sl,ech,...]) <= 1.1).all():\n",
    "                rem_sl.append(sl)\n",
    "                break\n",
    "        X_sc = np.max(X[sl,...])\n",
    "        X[sl,...] /= X_sc\n",
    "    X = np.delete(X,rem_sl,axis=0)\n",
    "    X = np.concatenate([np.real(X),np.imag(X)],axis=-1)  # (num_echoes, H, W, 2)\n",
    "elif data_sel.value == 'NIFTI':\n",
    "    dicom_files = sorted([os.path.join(file_dir, f) for f in os.listdir(file_dir)\n",
    "                          if f.endswith(\".nii.gz\")])\n",
    "    avoid_comps = ['imaginary','real','Eq']\n",
    "    dicom_files = sorted([f for f in dicom_files if not any(char in f for char in avoid_comps)])\n",
    "    # print(dicom_files)\n",
    "\n",
    "    nifti_file = dicom_files[0]\n",
    "    fn_noEch = nifti_file.split(\"_e\")[0]\n",
    "\n",
    "    # Load NIfTI image\n",
    "    img = nib.load(nifti_file)\n",
    "    data = img.get_fdata(dtype=np.float32)  # shape: (X, Y, Z, echoes?) or (X, Y, Z)\n",
    "    \n",
    "    # Load JSON sidecar (contains echo times, etc.)\n",
    "    json_file = nifti_file.replace(\".nii.gz\", \".json\")\n",
    "    metadata = {}\n",
    "    if os.path.exists(json_file):\n",
    "        with open(json_file, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "    # Define useful parameters\n",
    "    ne = metadata[\"EchoTrainLength\"]\n",
    "\n",
    "    # Generate multi-echo volume to be filled\n",
    "    V_shape = list(data.shape)\n",
    "    V_shape.insert(2, ne)\n",
    "    V = np.zeros(V_shape+[2], dtype=np.float32)\n",
    "    TE = np.zeros((V_shape[-1],ne), dtype=np.float32)\n",
    "    V_mag_all = np.zeros(V_shape, dtype=np.float32)\n",
    "\n",
    "    for ech in range(ne):\n",
    "        # Magnitude file processing\n",
    "        nifti_file_mag = fn_noEch + '_e' + str(ech+1) + '.nii.gz'\n",
    "        img_mag = nib.load(nifti_file_mag)\n",
    "        V_mag = img_mag.get_fdata(dtype=np.float32)\n",
    "\n",
    "        json_file_mag = nifti_file_mag.replace(\".nii.gz\", \".json\")\n",
    "        metadata_mag = {}\n",
    "        if os.path.exists(json_file_mag):\n",
    "            with open(json_file_mag, \"r\") as f:\n",
    "                metadata_mag = json.load(f)\n",
    "\n",
    "        V_mag_resc = np.array(V_mag) # / float(metadata_mag[\"PhilipsScaleSlope\"]);\n",
    "        if ech == 0:\n",
    "            V_sc = np.max(V_mag_resc)\n",
    "\n",
    "        # Phase file processing\n",
    "        nifti_file_ph = fn_noEch + '_e' + str(ech+1) + '_ph.nii.gz'\n",
    "        img_ph = nib.load(nifti_file_ph)\n",
    "        V_ph = img_ph.get_fdata(dtype=np.float32)\n",
    "\n",
    "        json_file_ph = nifti_file_ph.replace(\".nii.gz\", \".json\")\n",
    "        metadata_ph = {}\n",
    "        if os.path.exists(json_file_ph):\n",
    "            with open(json_file_ph, \"r\") as f:\n",
    "                metadata_ph = json.load(f)\n",
    "\n",
    "        V_ph_resc = np.array(V_ph) # / float(metadata_ph[\"PhilipsScaleSlope\"]);\n",
    "\n",
    "        # Combining into complex volume\n",
    "        if V_mag_resc.shape[2] == V_ph_resc.shape[2]:\n",
    "            V_ech = V_mag_resc * np.exp(1j*V_ph_resc) / V_sc;\n",
    "        else:\n",
    "            V_ech = np.zeros([V.shape[0],V.shape[1],V.shape[3]]);\n",
    "            print('\\tMismatch between mag and phase at echo:',str(ech))\n",
    "\n",
    "        if V.shape[3] == V_ech.shape[2]:\n",
    "            V[:,:,ech,:,0] = np.real(V_ech);\n",
    "            V[:,:,ech,:,1] = np.imag(V_ech);\n",
    "            TE[:,ech] = float(metadata_mag[\"EchoTime\"]);\n",
    "            V_mag_all[:,:,ech,:] = np.abs(V_ech)\n",
    "        else:\n",
    "            print('\\tMismatch between complex array and 1st echo at echo',str(ech))\n",
    "\n",
    "    # Get mask from the mean of all-echoes magnitudes\n",
    "    V_mag_mean = np.mean(V_mag_all,axis=2,keepdims=True)\n",
    "    V_mag_mean = np.expand_dims(np.repeat(V_mag_mean,ne,axis=2),axis=-1)\n",
    "    V_mag_mean = np.repeat(V_mag_mean,2,axis=-1)\n",
    "    V = np.where(V_mag_mean >= 0.05, V, 0.0)\n",
    "    \n",
    "    # Rearrange to obtain the required dimensionality\n",
    "    X = np.transpose(V, axes=[3,2,1,0,4]) # (num_slices, num_echoes, H, W, 2)\n",
    "    X = np.flip(X,axis=2)\n",
    "    TE = np.array(TE)\n",
    "elif data_sel.value == 'MAT':\n",
    "    mat = sio.loadmat(file_dir)\n",
    "    if 'imDataParams' in mat.keys():\n",
    "        acq = mat['imDataParams'][0,0][0].astype('complex64')\n",
    "        TE = mat['imDataParams'][0,0][1].astype('float32')\n",
    "    elif 'imDataAll' in  mat.keys():\n",
    "        acq = mat['imDataAll'][0,0][4].astype('complex64')\n",
    "        TE = mat['imDataAll'][0,0][0].astype('float32') #0/2\n",
    "    if acq.shape[0] % 16 != 0.0:\n",
    "        acq = acq[:(acq.shape[0]-acq.shape[0]%16)]\n",
    "    acq = np.transpose(acq, (2,4,0,1,3)) / np.max(np.abs(acq))\n",
    "    acq_real = np.real(acq)\n",
    "    acq_imag = np.imag(acq)\n",
    "    X = np.concatenate((acq_real,acq_imag),axis=-1)\n",
    "    X = np.flip(X,axis=0)\n",
    "elif data_sel.value == 'QSM':\n",
    "    mat = sio.loadmat(file_dir)\n",
    "    acq = mat['S'].astype('complex64')\n",
    "    TE = mat['TE'].astype('float32')\n",
    "    TE *= 1e-3\n",
    "    if acq.shape[0] % 16 != 0.0:\n",
    "        acq = acq[:(acq.shape[0]-acq.shape[0]%16)]\n",
    "    acq = np.transpose(acq, (2,3,0,1))\n",
    "    acq_real = np.real(np.expand_dims(acq,axis=-1))\n",
    "    acq_imag = np.imag(np.expand_dims(acq,axis=-1))\n",
    "    X = np.concatenate((acq_real,acq_imag),axis=-1)\n",
    "    #X = X[::3,...]\n",
    "TE = np.expand_dims(TE,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019ec41-50b5-4337-b907-c5a03da2569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "if data_sel.value == 'DICOM' or data_sel.value == 'NIFTI':\n",
    "    TE = tf.cast(TE, tf.float32)\n",
    "else:\n",
    "    TE = tf.repeat(TE, [X.shape[0]], axis=0)\n",
    "A_dataset = tf.data.Dataset.from_tensor_slices((X,TE))\n",
    "test_iter = cycle(A_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba2c12-6588-4310-88f4-d5bd5bd6975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc3a7a-e987-4fb9-a545-f23340c75eb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3634df1-edf1-4f7d-bfd3-8d695e9fc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = widgets.Dropdown(\n",
    "    options=['U-Net','MDWF-Net','2D-Net','VET-Net','AI-DEAL','Single','Mag'],\n",
    "    value='VET-Net',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee026ea-3e43-4613-a72c-d9783927b208",
   "metadata": {},
   "source": [
    "The original training dataset had CSE-MRI data from 149 subjects. However, all the models have different versions that were trained using different ratios of real and synthetic data. In the following menu, you can choose the version that you want to use depending on the number of subjects whose (real) data that was used for training.\n",
    "\n",
    "* *Disclaimer:* In the cases of U-Net and MDWF-Net, this option is only valid for 6-echo models; there is only a single 3-echo version for each of them and they were trained using real data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f820ec-d8a4-47cf-bf88-806ae6a0dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratio_sel = widgets.Dropdown(\n",
    "    options=[0,3,9,15,149],\n",
    "    value=149,\n",
    "    description='Real subjects considered for training:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_ratio_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0cc663-a68b-4516-a61c-d32c468e9fcf",
   "metadata": {},
   "source": [
    "Additionally, you can also set the number of echoes to be considered as input. This parameter will change the imported version of U-Net and MDWF-Net models, while the remaining models will not depend on this value as they are able to handle different echo train lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71a24c-8c95-4dd8-8195-2fe6338efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_sel = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=2,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Num. Echoes:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "ech_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a0d5f-5b97-4a0f-8857-f11c7938ea6f",
   "metadata": {},
   "source": [
    "For those models that use least squares to calculate water-fat signals after demodulating the CSE-MR signal (VET-Net & AI-DEAL), you can also choose to discard the first echo, since it has been demonstrated that its phase is usually corrupted (see [Hernando et al. (2012), *Addressing phase errors in fat‐water imaging using a mixed magnitude/complex fitting method*](https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.23044))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc109ff-ce8a-4952-91dd-4553c29c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ech1 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Remove first echo',\n",
    ")\n",
    "remove_ech1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4850f23a-416a-4103-ae47-9719fc198c43",
   "metadata": {},
   "source": [
    "Optionally, you can also enable the resoultion of the water-fat separation using a phase-constrained least squares approach. By doing this, you are ensuring that the phase of the water-only and the fat-only signals are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d5cbd-e621-434d-8bd0-1022f8d58676",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_const = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Phase-constrained LS',\n",
    ")\n",
    "phase_const"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7c1e1-d496-4bcd-b8f4-1883ddbcd6d1",
   "metadata": {},
   "source": [
    "Finally, you have to specify the way in which PDFF is going to be calculated:\n",
    "1) Magnitude-based: $$PDFF = \\frac{|\\rho_F|}{|\\rho_W|+|\\rho_F|}$$\n",
    "2) Using magnitude discrimination: $$PDFF = \\begin{cases} \\frac{|\\rho_F|}{|\\rho_W+\\rho_F|} & ,~if~~|\\rho_F|>|\\rho_W| \\\\ 1-\\frac{|\\rho_W|}{|\\rho_W+\\rho_F|} & ,~else \\end{cases}$$\n",
    "\n",
    "If you choose the **phase-constrained solution, both PDFF definitions will be equal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3f715-7bfd-4131-9421-d0d46cc3992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_def = widgets.Dropdown(\n",
    "    options=['Magnitude-based','Magnitude-discrimination'],\n",
    "    value='Magnitude-based',\n",
    "    description='PDFF definition',\n",
    "    disabled=False,\n",
    ")\n",
    "pdff_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378e143-b76b-47e7-933d-d9d5b70debbb",
   "metadata": {},
   "source": [
    "_Experimental:_ There is an ongoing development of a VET-Net model for 3T CSE-MRI. You can enable the 3T model by clicking the box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b724f791-9851-4634-86e4-4ff6dd4bf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_3p0 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='3T Model',\n",
    ")\n",
    "enable_3p0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bdd7fa-8a74-4a4c-8148-1d6fd6f9025d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Building the model's architecture and loading the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088ea10-61e0-4921-8c8c-eb57b40d987d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_sel.value == 'U-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-202'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-403'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-402'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-401'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-400'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-203'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,2*ech_sel.value), n_out=2, filters=args.n_G_filters,output_activation='relu')\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'MDWF-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-204'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-404'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-405'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-406'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-407'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-205'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.MDWF_Generator(input_shape=(None,None,2*ech_sel.value), filters=args.n_G_filters, \n",
    "                              WF_self_attention=args.D1_SelfAttention, R2_self_attention=args.D2_SelfAttention,\n",
    "                              FM_self_attention=args.D3_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == '2D-Net':\n",
    "    model_fn = 'Sup-200'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.PM_Generator(input_shape=(None,None,2*ech_sel.value), te_input=False, ME_layer=None, filters=args.n_G_filters)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'VET-Net':\n",
    "    if enable_3p0.value:\n",
    "        model_fn = 'TEaug-301'\n",
    "    else:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'TEaug-300'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'TEaug-311'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'TEaug-310'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'TEaug-309'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'TEaug-308'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.PM_Generator(input_shape=(None,None,None,2), te_input=True, te_shape=(None,), filters=args.n_G_filters)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'AI-DEAL':\n",
    "    experiment_dir = py.join('output','Unsup-313') #306\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,None,2), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    self_attention=args.D1_SelfAttention)\n",
    "    G_A2R2= dl.UNet(input_shape=(None,None,None,1), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    output_activation='sigmoid', self_attention=args.D2_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B, G_A2R2=G_A2R2), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'Single':\n",
    "    experiment_dir = py.join('output','Single-224')\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_mag = dl.UNet(input_shape=(None,None,None,1),n_out=3,ME_layer=True,filters=args.n_G_filters,\n",
    "                output_activation='sigmoid',self_attention=args.D1_SelfAttention)\n",
    "    G_pha = dl.UNet(input_shape=(None,None,None,1),n_out=4,ME_layer=True,filters=args.n_G_filters,\n",
    "                    output_activation='linear',self_attention=args.D2_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_mag=G_mag, G_pha=G_pha), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'Mag':\n",
    "    if enable_3p0.value:\n",
    "        model_fn = 'mag-002'\n",
    "    else:\n",
    "        model_fn = 'mag-007' # 003/005\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_mag = dl.UNet(input_shape=(None,None,None,1),bayesian=(args.main_loss=='Rice'),ME_layer=True,filters=args.n_G_filters,\n",
    "                    te_input=(args.training_mode=='supervised' and args.n_echoes==0),te_shape=(None,),\n",
    "                    output_activation='sigmoid',self_attention=args.D1_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_mag=G_mag), py.join(experiment_dir, 'checkpoints'))\n",
    "\n",
    "try:  # restore checkpoint including the epoch counter\n",
    "    checkpoint.restore().assert_existing_objects_matched()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc3edd-57a9-4b5d-9e17-9f0a48f6b1ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preparing the PDFF estimation workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ce21f-c096-4589-9f4e-c3b13e16e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function\n",
    "@tf.function\n",
    "def sample(A, TE):\n",
    "    if A.shape[1] > ech_sel.value:\n",
    "        A = A[:,:ech_sel.value,...]\n",
    "        TE = TE[:,:ech_sel.value,...]\n",
    "    A_abs = tf.math.sqrt(tf.reduce_sum(tf.square(A), axis=-1, keepdims=True))\n",
    "    A_msk = tf.reduce_mean(A_abs, axis=1, keepdims=True)\n",
    "    A2B_msk = tf.concat([A_msk,A_msk], axis=-1)\n",
    "    if model_sel.value == 'U-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B_WF_abs = G_A2B(A_pf, training=False)\n",
    "        A2B_WF_abs = tf.expand_dims(A2B_WF_abs, axis=1)\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, tf.zeros_like(A2B_WF[:,:1,...])], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'MDWF-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B = G_A2B(A_pf, training=False)\n",
    "        A2B = tf.expand_dims(A2B, axis=1)\n",
    "        A2B_PM = A2B[...,-1:-3:-1]\n",
    "        A2B_WF_abs = A2B[...,:2]\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == '2D-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B_PM = G_A2B(A_pf, training=False)\n",
    "        A2B_PM = tf.expand_dims(A2B_PM, axis=1)\n",
    "        A2B_PM = A2B_PM[...,::-1]\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF = wf.get_rho(A[:,1:,...], A2B_PM, te=TE[:,1:,...])\n",
    "        else:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, te=TE, phase_constraint=phase_const.value)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'VET-Net':\n",
    "        A2B_PM = G_A2B([A,TE], training=False) #[:,:ech_sel.value,...]\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF = wf.get_rho(A[:,1:,...], A2B_PM, te=TE[:,1:,...])\n",
    "        elif enable_3p0.value:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, field=3.0, te=TE, phase_constraint=phase_const.value)\n",
    "        else:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, te=TE, phase_constraint=phase_const.value)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'AI-DEAL':\n",
    "        A2B_var_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        A2B_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_FM = G_A2B(A[:,1:,...], training=False)\n",
    "        else:\n",
    "            A2B_FM = G_A2B(A, training=False)\n",
    "        A2B_R2 = G_A2R2(A_abs, training=False)\n",
    "        A2B_PM = tf.concat([A2B_FM.mean(),A2B_R2.mean()],axis=-1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A[:,1:,...], A2B_FM, A2B_R2, te=TE[:,1:,...], rem_R2=False)\n",
    "        else:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A, A2B_FM, A2B_R2, te=TE, rem_R2=False)\n",
    "        A2B_WF_var = tf.concat([A2B_WF_var,tf.zeros_like(A2B_WF_var)],axis=-1)\n",
    "        A2B_PM_var = tf.concat([A2B_FM.variance(),A2B_R2.sigma],axis=-1)\n",
    "        A2B_var = tf.concat([A2B_WF_var,A2B_PM_var], axis=1)\n",
    "        A2B_var = tf.where(A2B_var_msk>=5e-2, A2B_var, 1e-12)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "    elif model_sel.value == 'Single':\n",
    "        A_pha = tf.math.atan2(A[...,1:],A[...,:1]) / np.pi\n",
    "        A2B_abs = G_mag(A_abs, training=False)\n",
    "        A2B_pha = G_pha(A_pha, training=False)\n",
    "        A2B_WF_abs = A2B_abs[...,:2]\n",
    "        A2B_WF_pha = A2B_pha[...,:2]\n",
    "        A2B_WF_r = A2B_WF_abs * tf.math.cos(4*np.pi*A2B_WF_pha)\n",
    "        A2B_WF_i = A2B_WF_abs * tf.math.sin(4*np.pi*A2B_WF_pha)\n",
    "        A2B_WF = tf.concat([A2B_WF_r,A2B_WF_i],axis=1)\n",
    "        A2B_WF = tf.transpose(A2B_WF,perm=[0,4,2,3,1])\n",
    "        A2B_PM = tf.concat([A2B_pha[...,2:3],A2B_abs[...,2:]],axis=-1)\n",
    "        A2B_bip = tf.concat([A2B_pha[...,-1:],tf.zeros_like(A2B_pha[...,-1:])],axis=-1)\n",
    "        A2B = tf.concat([A2B_WF,A2B_PM,A2B_bip],axis=1)\n",
    "        A2B_bip_msk = tf.repeat(A_msk,4,axis=1)\n",
    "        A2B = tf.where(A2B_bip_msk>=5e-2, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'Mag':\n",
    "        if args.main_loss == 'Rice':\n",
    "            A2B_R2_prob = G_mag([A_abs, TE], training=False)\n",
    "            A2B_R2 = A2B_R2_prob.mean()\n",
    "        elif args.training_mode == 'supervised':\n",
    "            A2B_R2 = G_mag([A_abs, TE], training=False)\n",
    "        else:\n",
    "            A2B_R2 = G_mag(A_abs, training=False)\n",
    "        A2B_R2 = tf.where(A_abs[:,:1,...]!=0.0,A2B_R2,0.0)\n",
    "        A2B_WF_abs, A2B2A_abs, A2B_WF_var = wf.CSE_mag(A_abs, A2B_R2, [args.field, TE], uncertainty=True)\n",
    "        A2B2A_abs = tf.where(A_abs!=0.0,A2B2A_abs,0.0)\n",
    "        A2B_PM = tf.concat([tf.zeros_like(A2B_R2),A2B_R2],axis=-1)\n",
    "        A2B_WF = tf.concat([A2B_WF_abs,tf.zeros_like(A2B_WF_abs)],axis=-1)\n",
    "        A2B = tf.concat([A2B_WF,A2B_PM],axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-2, A2B, 0.0)\n",
    "        if args.main_loss == 'Rice':\n",
    "            A2B_PM_var = tf.concat([tf.zeros_like(A2B_R2_prob.variance()),A2B_R2_prob.variance()], axis=-1)\n",
    "            A2B_WF_var = tf.concat([A2B_WF_var,tf.zeros_like(A2B_WF_var)], axis=-1)\n",
    "            A2B_var = tf.concat([tf.zeros_like(A2B_WF_var),A2B_WF_var,A2B_WF_var,\n",
    "                                 tf.zeros_like(A2B_WF_var),A2B_PM_var], axis=1)\n",
    "        else:\n",
    "            A2B_var = None\n",
    "    return A2B, A2B_var\n",
    "\n",
    "def test(A, TE=None):\n",
    "    A2B, A2B_var = sample(A, TE)\n",
    "    return A2B, A2B_var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6bc697-6c87-44c6-8728-4364ee92c206",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Slice-by-slice loading and testing\n",
    "Each time that you run the following cell, you will be moving one slide down. The next cells will execute the water-fat separation and PDFF quantification for the chosen slice. Please first choose the number of slices that you want to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f343e5-ff93-4cf6-9709-ed3351cb3fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_slices = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=X.shape[0],\n",
    "    step=1,\n",
    "    description='Num. slices:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "run_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c9559-84b7-433a-8b90-42a83294c0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(run_slices.value):\n",
    "    A, TE = next(test_iter)\n",
    "    A = tf.expand_dims(A,axis=0)\n",
    "    TE = tf.expand_dims(TE,axis=0)\n",
    "    A2B, A2B_var = test(A, TE)\n",
    "    i+=1\n",
    "    \n",
    "    # CSE-MR images at each echo\n",
    "    mag_ech1 = np.squeeze(np.abs(tf.complex(A[:,0,:,:,0],A[:,0,:,:,1])))\n",
    "    pha_ech1 = np.squeeze(np.arctan2(A[:,0,:,:,1],A[:,0,:,:,0]))\n",
    "    mag_ech2 = np.squeeze(np.abs(tf.complex(A[:,1,:,:,0],A[:,1,:,:,1])))\n",
    "    pha_ech2 = np.squeeze(np.arctan2(A[:,1,:,:,1],A[:,1,:,:,0]))\n",
    "    mag_ech3 = np.squeeze(np.abs(tf.complex(A[:,2,:,:,0],A[:,2,:,:,1])))\n",
    "    pha_ech3 = np.squeeze(np.arctan2(A[:,2,:,:,1],A[:,2,:,:,0]))\n",
    "    \n",
    "    # Estimated quantitative maps\n",
    "    w_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1],A2B[:,0,:,:,1:])),axis=0)\n",
    "    w_p_aux = np.squeeze(tf.math.atan2(A2B[:,0,:,:,1],A2B[:,0,:,:,0]))\n",
    "    f_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,1,:,:,:1],A2B[:,1,:,:,1:])),axis=0)\n",
    "    f_p_aux = np.squeeze(tf.math.atan2(A2B[:,1,:,:,1],A2B[:,1,:,:,0]))\n",
    "    wf_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1]+A2B[:,1,:,:,:1],A2B[:,0,:,:,1:]+A2B[:,1,:,:,1:])),axis=0)\n",
    "    r2_aux = np.squeeze(A2B[:,2,:,:,1])\n",
    "    field_aux = np.squeeze(A2B[:,2,:,:,0])\n",
    "    if pdff_def.value == 'Magnitude-based':\n",
    "        PDFF_aux = f_m_aux/(w_m_aux+f_m_aux)\n",
    "    elif pdff_def.value == 'Magnitude-discrimination':\n",
    "        PDFF_aux = np.where(f_m_aux >= w_m_aux, f_m_aux/wf_m_aux, 1-(w_m_aux/wf_m_aux))\n",
    "    PDFF_aux[np.isnan(PDFF_aux)] = 0.0\n",
    "    # Update maps to be saved in MAT file\n",
    "    F.append(PDFF_aux*100.0)\n",
    "    P.append(np.expand_dims(field_aux*fm_sc, axis=-1))\n",
    "    R.append(np.expand_dims(np.concatenate([w_m_aux,f_m_aux],axis=-1), axis=-2))\n",
    "    R2.append(np.expand_dims(r2_aux*r2_sc, axis=-1))\n",
    "    \n",
    "    # Estimated uncertainty maps (if available)\n",
    "    if A2B_var is not None:\n",
    "        W_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,0,:,:,:1],A2B_var[:,0,:,:,1:])),axis=0)\n",
    "        WF_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,1,:,:,:1],A2B_var[:,1,:,:,1:])),axis=0)\n",
    "        F_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,3,:,:,:1],A2B_var[:,3,:,:,1:])),axis=0)\n",
    "        r2s_var = np.squeeze(A2B_var[:,-1,:,:,1:],axis=0)*(r2_sc**2)\n",
    "        field_var = np.squeeze(A2B_var[:,-1,:,:,:1],axis=0)*(fm_sc**2)\n",
    "    \n",
    "        Aux_WF = np.where(f_m_aux>=w_m_aux, f_m_aux, w_m_aux)\n",
    "        Aux_WF_var = np.where(f_m_aux>=w_m_aux, F_var, W_var)\n",
    "        PDFF_var = Aux_WF_var/(Aux_WF**2)\n",
    "        PDFF_var -= 2 * WF_var / (Aux_WF*wf_m_aux)\n",
    "        PDFF_var += (W_var + F_var + 2*WF_var)/(wf_m_aux)\n",
    "        PDFF_var *= Aux_WF**2 / (wf_m_aux)**2 #[W_var,WF_var,F_var]\n",
    "        PDFF_var = np.nan_to_num(PDFF_var)\n",
    "        \n",
    "        # Update maps to be saved in MAT file\n",
    "        PDFF_vars.append(PDFF_var*1e4)\n",
    "        WF_vars.append(np.expand_dims(np.concatenate([W_var,WF_var,F_var],axis=-1), axis=-2))\n",
    "        R2_vars.append(r2s_var)\n",
    "        FM_vars.append(field_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab56ee-4bf1-44cd-b894-6298daea4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(16, 4), nrows=2, ncols=6)\n",
    "\n",
    "# Acquisitions in the first row\n",
    "acq_ech1 = axs[0,0].imshow(mag_ech1, cmap='gray',\n",
    "                      interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,0].set_title('Mag 1st Echo')\n",
    "axs[0,0].axis('off')\n",
    "acq_ech2 = axs[0,1].imshow(pha_ech1/np.pi, cmap='gist_earth',\n",
    "                      interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,1].set_title('Phase 1st Echo')\n",
    "axs[0,1].axis('off')\n",
    "acq_ech3 = axs[0,2].imshow(mag_ech2, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,2].set_title('Mag 2nd Echo')\n",
    "axs[0,2].axis('off')\n",
    "acq_ech4 = axs[0,3].imshow(pha_ech2/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,3].set_title('Phase 2nd Echo')\n",
    "axs[0,3].axis('off')\n",
    "acq_ech5 = axs[0,4].imshow(mag_ech3, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,4].set_title('Mag 3rd Echo')\n",
    "axs[0,4].axis('off')\n",
    "acq_ech6 = axs[0,5].imshow(pha_ech3/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,5].set_title('Phase 3rd Echo')\n",
    "axs[0,5].axis('off')\n",
    "\n",
    "# A2B maps in the second row\n",
    "W_ok =  axs[1,0].imshow(w_m_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "\n",
    "Wp_ok =  axs[1,1].imshow(w_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Wp_ok, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "F_ok =  axs[1,2].imshow(f_m_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=axs[1,2])\n",
    "axs[1,2].axis('off')\n",
    "\n",
    "Fp_ok =  axs[1,3].imshow(f_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Fp_ok, ax=axs[1,3])\n",
    "axs[1,3].axis('off')\n",
    "\n",
    "r2_ok = axs[1,4].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[1,4])\n",
    "axs[1,4].axis('off')\n",
    "\n",
    "field_ok =  axs[1,5].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=axs[1,5])\n",
    "axs[1,5].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.8)\n",
    "fig.set_facecolor(\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cf2a4-b2f1-458a-9a48-0625ed48c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "if A2B_var is not None:\n",
    "    fig, axs = plt.subplots(figsize=(15, 4), nrows=2, ncols=5)\n",
    "\n",
    "    # Estimated maps\n",
    "    FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "    axs[0,0].axis('off')\n",
    "    W_ok =  axs[0,1].imshow(w_m_aux, cmap='bone',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(W_ok, ax=axs[0,1])\n",
    "    axs[0,1].axis('off')\n",
    "\n",
    "    F_ok =  axs[0,2].imshow(f_m_aux, cmap='pink',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(F_ok, ax=axs[0,2])\n",
    "    axs[0,2].axis('off')\n",
    "\n",
    "    r2_ok = axs[0,3].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                            interpolation='none', vmin=0, vmax=r2_sc)\n",
    "    fig.colorbar(r2_ok, ax=axs[0,3])\n",
    "    axs[0,3].axis('off')\n",
    "\n",
    "    field_ok =  axs[0,4].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                                interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "    fig.colorbar(field_ok, ax=axs[0,4])\n",
    "    axs[0,4].axis('off')\n",
    "    \n",
    "    WF_uq = axs[1,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "    fig.colorbar(WF_uq, ax=axs[1,0])\n",
    "    axs[1,0].axis('off')\n",
    "\n",
    "    W_uq = axs[1,1].matshow(W_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "    fig.colorbar(W_uq, ax=axs[1,1])\n",
    "    axs[1,1].axis('off')\n",
    "\n",
    "    F_uq = axs[1,2].matshow(F_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-5,vmax=1e0))\n",
    "    fig.colorbar(F_uq, ax=axs[1,2])\n",
    "    axs[1,2].axis('off')\n",
    "\n",
    "    r2s_uq=axs[1,3].matshow(r2s_var, cmap='gnuplot',\n",
    "                          norm=LogNorm(vmin=1e1,vmax=1e4))\n",
    "    fig.colorbar(r2s_uq, ax=axs[1,3])\n",
    "    axs[1,3].axis('off')\n",
    "\n",
    "    field_uq = axs[1,4].matshow(field_var, cmap='gnuplot2',\n",
    "                                norm=LogNorm(vmin=1e-6,vmax=1e-3))\n",
    "    fig.colorbar(field_uq, ax=axs[1,4])\n",
    "    axs[1,4].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0bb1e3-6882-4e3c-afef-350fa851d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "plt.matshow(PDFF_aux*100.0,cmap='jet',vmin=0.0,vmax=100.0, fignum=1)\n",
    "# plt.matshow(PDFF_var*1e4, cmap='gnuplot2',vmin=0,vmax=1e2, fignum=1)\n",
    "# plt.matshow(r2_aux*r2_sc, cmap='copper', vmin=0, vmax=r2_sc, fignum=1)\n",
    "# plt.matshow(np.where(r2_aux!=0.0,np.squeeze(r2s_var),0.0), cmap='gnuplot', vmin=0,vmax=20, fignum=1)\n",
    "# plt.matshow(w_m_aux, cmap='bone', vmin=0, vmax=1, fignum=1)\n",
    "# plt.matshow(f_m_aux, cmap='pink', vmin=0, vmax=1, fignum=1)\n",
    "# plt.matshow(np.where(PDFF_aux!=0.0,WF_var,0.0), cmap='gnuplot2', vmin=0, vmax=1, fignum=1)\n",
    "# plt.matshow(field_aux*fm_sc,cmap='twilight',fignum=1)\n",
    "# plt.matshow(A2B[0,3,:,:,0],cmap='twilight',vmin=-.5,vmax=.5,fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34e6f5-ef76-4f44-abaa-9645577ab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_pha = tf.math.atan2(A[...,1:],A[...,:1]) / np.pi\n",
    "# A_pha = np.angle(acq[:1,...]) \n",
    "# A2B_pha = G_pha(A_pha, training=False)\n",
    "\n",
    "x = tf.linspace(-.5,.5,A.shape[2])\n",
    "X, Y = tf.meshgrid(x, x)\n",
    "B_bp = tf.roll(X,shift=A.shape[2]//2,axis=1) #tf.where(field_aux!=0.0,X,0.0)\n",
    "\n",
    "# B_diff = B_bp[:,96:192] + B_bp[:,-97:-(192+1):-1] # left half\n",
    "# B_diff = B_bp[:,-97:-192:-1] # right half\n",
    "\n",
    "B_bp_tf = tf.expand_dims(B_bp,axis=0)\n",
    "B_bp_tf = tf.expand_dims(B_bp_tf,axis=-1)\n",
    "BP_dy, BP_dx = tf.image.image_gradients(B_bp_tf)\n",
    "\n",
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "plt.matshow(np.squeeze(BP_dx))#,cmap='twilight',vmin=-1,vmax=1,fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab33ad-1d8d-4808-b00b-4f881c7ad354",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Export results to a MAT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac4aa5-4df8-4440-9870-6d252d3c6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_sel.value == 'QSM':\n",
    "    out_id = file_dir.split('/')[-1].split('.')[0]\n",
    "else:\n",
    "    out_id = file_dir.split('/')[-2].split('_')[-1]\n",
    "listdir = file_dir.split('/')[:-1]\n",
    "listdir.append('res_MP_' + ''.join(model_sel.value.split('-')) + '_' + out_id + '.mat')\n",
    "outpath = '/'.join(listdir)\n",
    "\n",
    "outvars = {'F': np.concatenate(F,axis=-1),\n",
    "           'P': np.concatenate(P,axis=-1),\n",
    "           'R': np.concatenate(R,axis=-2),\n",
    "           'R2':np.concatenate(R2,axis=-1),\n",
    "           'mthd': model_sel.value}\n",
    "\n",
    "if A2B_var is not None:\n",
    "    var_outvars = {'F_var': np.concatenate(PDFF_vars, axis=-1),\n",
    "                   'R_var': np.concatenate(WF_vars, axis=-2),\n",
    "                   'R2_var': np.concatenate(R2_vars, axis=-1),\n",
    "                   'P_var': np.concatenate(FM_vars, axis=-1)}\n",
    "    outvars.update(var_outvars)\n",
    "\n",
    "sio.savemat(outpath, outvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b68734-c333-4029-afc8-c9eec9b85359",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optional: Load reference results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe6362-e07c-4398-aa26-b590dd3f5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_JGalgani/004/results_MP_GC/IM_0007_anon_MP_GC.mat\"\n",
    "mat = sio.loadmat(out_file_dir)\n",
    "B_WF = np.flip(mat['R'].astype('complex64'),axis=-2)\n",
    "B_WF = B_WF / np.max(np.abs(np.sum(B_WF,axis=-1,keepdims=True)))\n",
    "B_R2 = np.flip(mat['R2'].astype('float32'),axis=-1)\n",
    "B_FM = np.flip(mat['P'].astype('float32'),axis=-1)\n",
    "B_PDFF = np.flip(mat['F'].astype('float32'),axis=-1)\n",
    "\n",
    "A_msk = np.abs(np.sum(B_WF,axis=-1,keepdims=False))>=5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c43d7e-1712-4f8e-a4e6-31919c450a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_W = np.expand_dims(mat['fwmc_w'].astype('float32'),axis=-1)\n",
    "B_F = np.expand_dims(mat['fwmc_f'].astype('float32'),axis=-1)\n",
    "B_WF = np.concatenate((B_W,B_F),axis=-1)\n",
    "B_WF = B_WF / np.max(np.abs(np.sum(B_WF,axis=-1,keepdims=True)))\n",
    "B_R2 = np.flip(mat['fwmc_r2star'].astype('float32'),axis=-1)\n",
    "B_FM = np.zeros_like(B_R2)\n",
    "B_PDFF = np.flip(mat['fwmc_ff'].astype('float32'),axis=-1)\n",
    "\n",
    "if B_W.shape[0] % 16 != 0.0:\n",
    "    B_W = B_W[:(B_W.shape[0]-B_W.shape[0]%16)]\n",
    "    B_F = B_F[:(B_F.shape[0]-B_F.shape[0]%16)]\n",
    "    B_WF= B_WF[:(B_WF.shape[0]-B_WF.shape[0]%16)]\n",
    "    B_R2= B_R2[:(B_R2.shape[0]-B_R2.shape[0]%16)]\n",
    "    B_FM = B_FM[:(B_FM.shape[0]-B_FM.shape[0]%16)]\n",
    "    B_PDFF= B_PDFF[:(B_PDFF.shape[0]-B_PDFF.shape[0]%16)]\n",
    "\n",
    "A_msk = np.abs(np.sum(B_WF,axis=-1,keepdims=False))>=50e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ef4b7f-0a62-48f9-859a-ba7c16491db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_PDFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dddf07f-4b86-4d0b-8842-b6a5f4752b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_aux = np.abs(B_WF[...,i-1:i,0]) *  A_msk[...,i-1:i] \n",
    "fn_aux = np.abs(B_WF[...,i-1:i,1]) *  A_msk[...,i-1:i] \n",
    "r2n_aux = np.squeeze(B_R2[...,i-1:i]) * A_msk[...,i-1]\n",
    "fieldn_aux = np.squeeze(B_FM[...,i-1:i]) * A_msk[...,i-1]\n",
    "PDFFn_aux = B_PDFF[...,i-1:i]/100.0 * A_msk[...,i-1:i]\n",
    "PDFF_aux = PDFF_aux * A_msk[...,i-1:i]\n",
    "\n",
    "fig,axs=plt.subplots(figsize=(12.7, 8), nrows=4, ncols=5)\n",
    "\n",
    "# Estimated maps in the first row\n",
    "FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "axs[0,0].axis('off')\n",
    "W_ok =  axs[0,1].imshow(w_m_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=axs[0,1])\n",
    "axs[0,1].axis('off')\n",
    "F_ok =  axs[0,2].imshow(f_m_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=axs[0,2])\n",
    "axs[0,2].axis('off')\n",
    "r2_ok = axs[0,3].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[0,3])\n",
    "axs[0,3].axis('off')\n",
    "field_ok =  axs[0,4].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=axs[0,4])\n",
    "axs[0,4].axis('off')\n",
    "\n",
    "# Ground-truth maps in the second row\n",
    "FF_gt = axs[1,0].imshow(PDFFn_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_gt, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "W_gt =  axs[1,1].imshow(wn_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_gt, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "F_gt =  axs[1,2].imshow(fn_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_gt, ax=axs[1,2])\n",
    "axs[1,2].axis('off')\n",
    "r2_gt = axs[1,3].imshow(r2n_aux, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_gt, ax=axs[1,3])\n",
    "axs[1,3].axis('off')\n",
    "field_gt =  axs[1,4].imshow(fieldn_aux, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_gt, ax=axs[1,4])\n",
    "axs[1,4].axis('off')\n",
    "\n",
    "# Error w.r.t. reference in the third row\n",
    "FF_est =axs[2,0].imshow(np.abs(PDFF_aux-PDFFn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(FF_est, ax=axs[2,0])\n",
    "axs[2,0].axis('off')\n",
    "W_est = axs[2,1].imshow(np.abs(w_m_aux-wn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(W_est, ax=axs[2,1])\n",
    "axs[2,1].axis('off')\n",
    "\n",
    "F_est = axs[2,2].imshow(np.abs(f_m_aux-fn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(F_est, ax=axs[2,2])\n",
    "axs[2,2].axis('off')\n",
    "\n",
    "r2_est= axs[2,3].imshow(np.abs(r2_aux*r2_sc-r2n_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(r2_est, ax=axs[2,3])\n",
    "axs[2,3].axis('off')\n",
    "\n",
    "field_est = axs[2,4].imshow(np.abs(field_aux*fm_sc-fieldn_aux), cmap='gray',\n",
    "                            interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(field_est, ax=axs[2,4])\n",
    "axs[2,4].axis('off')\n",
    "\n",
    "# Uncertainty maps in the fourth row\n",
    "if A2B_var is None:\n",
    "    PDFF_var = PDFFn_aux * 0.0\n",
    "    W_var = PDFFn_aux * 0.0\n",
    "    F_var = PDFFn_aux * 0.0\n",
    "    r2s_var = PDFFn_aux * 0.0\n",
    "    field_var = PDFFn_aux * 0.0\n",
    "WF_uq = axs[3,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                         norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "fig.colorbar(WF_uq, ax=axs[3,0])\n",
    "axs[3,0].axis('off')\n",
    "W_uq = axs[3,1].matshow(W_var, cmap='gnuplot2',\n",
    "                        norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "fig.colorbar(W_uq, ax=axs[3,1])\n",
    "axs[3,1].axis('off')\n",
    "F_uq = axs[3,2].matshow(F_var, cmap='gnuplot2',\n",
    "                        norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "fig.colorbar(F_uq, ax=axs[3,2])\n",
    "axs[3,2].axis('off')\n",
    "r2s_uq=axs[3,3].matshow(r2s_var, cmap='gnuplot',\n",
    "                        norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "fig.colorbar(r2s_uq, ax=axs[3,3])\n",
    "axs[3,3].axis('off')\n",
    "field_uq = axs[3,4].matshow(field_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-5,vmax=1e-2))\n",
    "fig.colorbar(field_uq, ax=axs[3,4])\n",
    "axs[3,4].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2071f-303e-4d16-baae-3eb0a1c41d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(figsize=(5, 8), nrows=4, ncols=2)\n",
    "\n",
    "# Estimated maps in the first row\n",
    "FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "axs[0,0].axis('off')\n",
    "r2_ok = axs[0,1].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[0,1])\n",
    "axs[0,1].axis('off')\n",
    "\n",
    "# Ground-truth maps in the second row\n",
    "FF_gt = axs[1,0].imshow(PDFFn_aux, cmap='jet',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(FF_gt, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "r2_gt = axs[1,1].imshow(r2n_aux, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_gt, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "# Error w.r.t. reference in the third row\n",
    "FF_est =axs[2,0].imshow(np.abs(PDFF_aux-PDFFn_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=0.2)\n",
    "fig.colorbar(FF_est, ax=axs[2,0])\n",
    "axs[2,0].axis('off')\n",
    "r2_est= axs[2,1].imshow(np.abs(r2_aux*r2_sc-r2n_aux), cmap='gray',\n",
    "                        interpolation='none', vmin=0.0, vmax=r2_sc/5)\n",
    "fig.colorbar(r2_est, ax=axs[2,1])\n",
    "axs[2,1].axis('off')\n",
    "\n",
    "# Uncertainty maps in the fourth row\n",
    "WF_uq = axs[3,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                         norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "fig.colorbar(WF_uq, ax=axs[3,0])\n",
    "axs[3,0].axis('off')\n",
    "r2s_uq=axs[3,1].matshow(r2s_var, cmap='gnuplot',\n",
    "                        norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "fig.colorbar(r2s_uq, ax=axs[3,1])\n",
    "axs[3,1].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5e44a-28ad-473c-a9e1-39c63451f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4)) # (width,height)\n",
    "# plt.matshow(PDFFn_aux*100.0,cmap='jet',vmin=0.0,vmax=100.0, fignum=1)\n",
    "plt.matshow(np.abs(PDFF_aux-PDFFn_aux)*100.0, cmap='gray', vmin=0, vmax=20, fignum=1)\n",
    "plt.colorbar()\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22711afe-4171-4c06-aee7-7e7a7a67f0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
