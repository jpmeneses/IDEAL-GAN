{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef027949-c23c-4e44-8696-59933df1b9fd",
   "metadata": {},
   "source": [
    "# Trying Deep Learning models for MRI-based Water-fat separation\n",
    "In this notebook, you can upload your own Chemical Shift-Encoded (CSE)-MR images and obtain the separated water-fat signals using the different DL-based models developed in this project. All of them were developed to work only with CSE-MR images obtained at **1.5T** scanners.\n",
    "\n",
    "The accepted data formats to upload your data are:\n",
    "* DICOM files\n",
    "* MAT files - using the [ISMRM Water-Fat Toolbox](https://www.ismrm.org/workshops/FatWater12/data.htm) format\n",
    "\n",
    "The available DL models for testing are:\n",
    "* U-Net\n",
    "* Multi-Decoder Water-Fat separation Network (MDWF-Net) - Refer to [DOI:10.1007/s00330-023-09576-2](https://doi.org/10.1007/s00330-023-09576-2)\n",
    "* Variable Echo Times neural Network (VET-Net) - Refer to [DOI:10.1007/s00330-024-11164-x](https://doi.org/10.1007/s00330-024-11164-x)\n",
    "* Artificial Intelligence-based Decomposition of water and fat with Echo asymmetry and Least squares estimation (AI-DEAL) - Soon to be published!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00c47bb-db5c-4d36-be92-47969ae04fd0",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e60782-ce5e-4df2-b7d0-060e95c4bce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_modality_lut\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from itertools import cycle\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74bc1f-eba0-4130-927c-733e63438753",
   "metadata": {},
   "source": [
    "Optionally, you can disable any available GPU. This is useful if your GPU's size is not enough to handle the data arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c4a31-3ac5-4e17-bc39-5dcfe7ea2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a0c3a-44f3-4c9c-888e-0b64dc14f76a",
   "metadata": {},
   "source": [
    "Finally, we the customized libraries included in this repository are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6532dd9-fd8b-48bd-b41b-8b5cbd4b2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2lib as tl\n",
    "import DLlib as dl\n",
    "import pylib as py\n",
    "import wflib as wf\n",
    "import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced9452-f60b-4ce1-b034-b7f40fa3af1b",
   "metadata": {},
   "source": [
    "## Loading CSE-MRI data\n",
    "First, the dataset directory must be specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72642abc-c28e-449f-a89b-2fcffbb27c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directory - Read DICOM files\n",
    "# file_dir = \"C:/Users/jpmen/Documents/FF-mat/2D_NSA1_ORIG_IM_0016/2D_NSA1_ORIG.mat\"\n",
    "file_dir = 'C:/Users/jpmen/OneDrive - Universidad Católica de Chile/Documents/MRI-Datasets/Anon_JGalgani/004/2D_NSA1_24S_2MM_IM_0007_anon/2D_NSA1_24S_2MM_IM_0007_anon.mat'\n",
    "# file_dir = \"C:/Users/jpmen/OneDrive - Universidad Católica de Chile\\Documents\\MRI-Datasets\\PDFF_Phantom_Data\\datasets\\site2_1p5T_protocol1.mat\"\n",
    "\n",
    "# Future output variables\n",
    "F = list() # PDFF \n",
    "P = list() # FM \n",
    "R = list() # WF \n",
    "R2= list() # R2 \n",
    "\n",
    "# Uncertainty variables\n",
    "PDFF_vars = list()\n",
    "WF_vars = list()\n",
    "R2_vars = list()\n",
    "FM_vars = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff83cedf-42fd-4159-8e46-1e988027c044",
   "metadata": {},
   "source": [
    "In the following block, you can choose the data format to be loaded. The default option is MAT files.\n",
    "\n",
    "It should be noted that the array shape within DICOM files can vary according to the scanner in which MR data was acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcace14-96e5-496b-b28c-fb3977614d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sel = widgets.Dropdown(\n",
    "    options=['MAT','DICOM'],\n",
    "    value='MAT',\n",
    "    description='Data format:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b23fc-0f69-4725-876e-6200a630cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_sel.value == 'DICOM':\n",
    "    ds = pydicom.dcmread(py.join(exp_dir,scan_fn))\n",
    "    if X_aux is None:\n",
    "        arr = ds.pixel_array #.transpose()\n",
    "        X_aux = apply_modality_lut(arr, ds).astype(np.float32)\n",
    "        X_aux = np.reshape(X_aux,(1,1,X_aux.shape[0],X_aux.shape[1],1))\n",
    "        TE_aux = np.array([[np.float(ds.EchoTime) * 1e-3]]).astype(np.float32)\n",
    "    else:\n",
    "        arr = ds.pixel_array #.transpose()\n",
    "        X_aux_2 = apply_modality_lut(arr, ds).astype(np.float32)\n",
    "        X_aux_2 = np.reshape(X_aux_2,(1,1,X_aux_2.shape[0],X_aux_2.shape[1],1))\n",
    "        TE_aux_2 = np.array([[np.float(ds.EchoTime) * 1e-3]]).astype(np.float32)\n",
    "        X_aux = np.concatenate((X_aux,X_aux_2), axis=0)\n",
    "        TE_aux = np.concatenate((TE_aux,TE_aux_2), axis=0)\n",
    "elif data_sel.value == 'MAT':\n",
    "    mat = sio.loadmat(file_dir)\n",
    "    if 'imDataParams' in mat.keys():\n",
    "        acq = mat['imDataParams'][0,0][0].astype('complex64')\n",
    "        TE = mat['imDataParams'][0,0][1].astype('float32')\n",
    "    elif 'imDataAll' in  mat.keys():\n",
    "        acq = mat['imDataAll'][0,0][4].astype('complex64')\n",
    "        TE = mat['imDataAll'][0,0][2].astype('float32') #0\n",
    "    if acq.shape[0] % 16 != 0.0:\n",
    "        acq = acq[:(acq.shape[0]-acq.shape[0]%16)]\n",
    "    acq = np.transpose(acq, (2,4,0,1,3)) / np.max(np.abs(acq))\n",
    "    acq_real = np.real(acq)\n",
    "    acq_imag = np.imag(acq)\n",
    "    X = np.concatenate((acq_real,acq_imag),axis=-1)\n",
    "    X = np.flip(X,axis=0)\n",
    "TE = np.expand_dims(TE,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019ec41-50b5-4337-b907-c5a03da2569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tensorflow dataset\n",
    "TEs = tf.repeat(TE, [X.shape[0]], axis=0)\n",
    "A_dataset = tf.data.Dataset.from_tensor_slices((X,TEs))\n",
    "test_iter = cycle(A_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc3a7a-e987-4fb9-a545-f23340c75eb9",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3634df1-edf1-4f7d-bfd3-8d695e9fc536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sel = widgets.Dropdown(\n",
    "    options=['U-Net', 'MDWF-Net', 'VET-Net','AI-DEAL'],\n",
    "    value='AI-DEAL',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "model_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee026ea-3e43-4613-a72c-d9783927b208",
   "metadata": {},
   "source": [
    "The original training dataset had CSE-MRI data from 149 subjects. However, all the models have different versions that were trained using different ratios of real and synthetic data. In the following menu, you can choose the version that you want to use depending on the number of subjects whose (real) data that was used for training.\n",
    "\n",
    "* *Disclaimer:* In the cases of U-Net and MDWF-Net, this option is only valid for 6-echo models; there is only a single 3-echo version for each of them and they were trained using real data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f820ec-d8a4-47cf-bf88-806ae6a0dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratio_sel = widgets.Dropdown(\n",
    "    options=[0,3,9,15,149],\n",
    "    value=149,\n",
    "    description='Real subjects considered for training:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_ratio_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0cc663-a68b-4516-a61c-d32c468e9fcf",
   "metadata": {},
   "source": [
    "Additionally, you can also set the number of echoes to be considered as input. This parameter will change the imported version of U-Net and MDWF-Net models, while the remaining models will not depend on this value as they are able to handle different echo train lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f71a24c-8c95-4dd8-8195-2fe6338efeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_sel = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=2,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Num. Echoes:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "ech_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a0d5f-5b97-4a0f-8857-f11c7938ea6f",
   "metadata": {},
   "source": [
    "Lastly, for those models that use least squares to calculate water-fat signals after demodulating the CSE-MR signal, you can also choose to discard the first echo, since it has been demonstrated that its phase is usually corrupted (see [Hernando et al. (2012), *Addressing phase errors in fat‐water imaging using a mixed magnitude/complex fitting method*](https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.23044))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc109ff-ce8a-4952-91dd-4553c29c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_ech1 = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Remove first echo',\n",
    ")\n",
    "remove_ech1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2088ea10-61e0-4921-8c8c-eb57b40d987d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if model_sel.value == 'U-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-202'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-403'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-402'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-401'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-400'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-203'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,2*ech_sel.value), n_out=2, filters=args.n_G_filters,output_activation='relu')\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'MDWF-Net':\n",
    "    if ech_sel.value == 6:\n",
    "        if data_ratio_sel.value == 149:\n",
    "            model_fn = 'Sup-204'\n",
    "        elif data_ratio_sel.value == 15:\n",
    "            model_fn = 'Sup-404'\n",
    "        elif data_ratio_sel.value == 9:\n",
    "            model_fn = 'Sup-405'\n",
    "        elif data_ratio_sel.value == 3:\n",
    "            model_fn = 'Sup-406'\n",
    "        elif data_ratio_sel.value == 0:\n",
    "            model_fn = 'Sup-407'\n",
    "    elif ech_sel.value == 3:\n",
    "        model_fn = 'Sup-205'\n",
    "    experiment_dir = py.join('output',model_fn)\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.MDWF_Generator(input_shape=(None,None,2*ech_sel.value), filters=args.n_G_filters, \n",
    "                              WF_self_attention=args.D1_SelfAttention, R2_self_attention=args.D2_SelfAttention,\n",
    "                              FM_self_attention=args.D3_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'VET-Net':\n",
    "    experiment_dir = py.join('output','TEaug-300')\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.PM_Generator(input_shape=(None,None,None,2), te_input=True, te_shape=(None,), filters=args.n_G_filters)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints'))\n",
    "elif model_sel.value == 'AI-DEAL':\n",
    "    experiment_dir = py.join('output','Unsup-110')\n",
    "    args = py.args_from_yaml(py.join(experiment_dir, 'settings.yml'))\n",
    "    G_A2B = dl.UNet(input_shape=(None,None,None,2), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    self_attention=args.D1_SelfAttention)\n",
    "    G_A2R2= dl.UNet(input_shape=(None,None,None,1), bayesian=True, ME_layer=True, filters=args.n_G_filters,\n",
    "                    output_activation='sigmoid', self_attention=args.D2_SelfAttention)\n",
    "    checkpoint = tl.Checkpoint(dict(G_A2B=G_A2B, G_A2R2=G_A2R2), py.join(experiment_dir, 'checkpoints'))\n",
    "\n",
    "try:  # restore checkpoint including the epoch counter\n",
    "    checkpoint.restore().assert_existing_objects_matched()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71ce21f-c096-4589-9f4e-c3b13e16e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function\n",
    "@tf.function\n",
    "def sample(A, TE):\n",
    "    A_abs = tf.math.sqrt(tf.reduce_sum(tf.square(A), axis=-1, keepdims=True))\n",
    "    A_msk = tf.reduce_mean(A_abs, axis=1, keepdims=True)\n",
    "    A2B_msk = tf.concat([A_msk,A_msk], axis=-1)\n",
    "    if A.shape[1] > ech_sel.value:\n",
    "        A = A[:,:ech_sel.value,...]\n",
    "    if model_sel.value == 'U-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B_WF_abs = G_A2B(A_pf, training=False)\n",
    "        A2B_WF_abs = tf.expand_dims(A2B_WF_abs, axis=1)\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, tf.zeros_like(A2B_WF[:,:1,...])], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-3, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'MDWF-Net':\n",
    "        A_pf = data.A_from_MEBCRN(A) # CHANGE TO NON-MEBCRN FORMAT\n",
    "        A2B = G_A2B(A_pf, training=False)\n",
    "        A2B = tf.expand_dims(A2B, axis=1)\n",
    "        A2B_PM = A2B[...,-1:-3:-1]\n",
    "        A2B_WF_abs = A2B[...,:2]\n",
    "        A2B_WF_abs = tf.transpose(A2B_WF_abs, perm=[0,4,2,3,1])\n",
    "        A2B_WF = tf.concat([A2B_WF_abs, tf.zeros_like(A2B_WF_abs)], axis=-1)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-3, A2B, 0.0)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'VET-Net':\n",
    "        A2B_PM = G_A2B([A,TE], training=False) #[:,:ech_sel.value,...]\n",
    "        A2B_PM = tf.where(A2B_msk>=5e-3, A2B_PM, 0.0)\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF = wf.get_rho(A[:,1:,...], A2B_PM, te=TE[:,1:,...])\n",
    "        else:\n",
    "            A2B_WF = wf.get_rho(A, A2B_PM, te=TE)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B_var = None\n",
    "    elif model_sel.value == 'AI-DEAL':\n",
    "        A2B_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        A2B_var_msk = tf.concat([A2B_msk,A2B_msk,A2B_msk,A2B_msk,A2B_msk], axis=1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_FM = G_A2B(A[:,1:,...], training=False)\n",
    "        else:\n",
    "            A2B_FM = G_A2B(A, training=False)\n",
    "        A2B_R2 = G_A2R2(A_abs, training=False)\n",
    "        A2B_PM = tf.concat([A2B_FM.mean(),A2B_R2.mean()],axis=-1)\n",
    "        if remove_ech1.value:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A[:,1:,...], A2B_FM, A2B_R2, te=TE[:,1:,...], rem_R2=False)\n",
    "        else:\n",
    "            A2B_WF, A2B_WF_var = wf.PDFF_uncertainty(A, A2B_FM, A2B_R2, te=TE, rem_R2=False)\n",
    "        A2B_WF_var = tf.concat([A2B_WF_var,tf.zeros_like(A2B_WF_var)],axis=-1)\n",
    "        A2B_PM_var = tf.concat([A2B_FM.variance(),A2B_R2.variance()],axis=-1)\n",
    "        A2B_var = tf.concat([A2B_WF_var,A2B_PM_var], axis=1)\n",
    "        if A.shape[1] >= A2B_var.shape[1]:\n",
    "            A2B_var = tf.where(tf.abs(A[:,:5,...])>=5e-3, A2B_var, 1e-10)\n",
    "        else:\n",
    "            A_aux = tf.concat([A,A],axis=1)\n",
    "            A2B_var = tf.where(A2B_msk>=5e-3, A2B_var, 1e-10)\n",
    "        A2B = tf.concat([A2B_WF, A2B_PM], axis=1)\n",
    "        A2B = tf.where(A2B_msk>=5e-3, A2B, 0.0)\n",
    "    return A2B, A2B_var\n",
    "\n",
    "def test(A, TE=None):\n",
    "    A2B, A2B_var = sample(A, TE)\n",
    "    return A2B, A2B_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c9559-84b7-433a-8b90-42a83294c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, TE = next(test_iter)\n",
    "A = tf.expand_dims(A,axis=0)\n",
    "TE = tf.expand_dims(TE,axis=0)\n",
    "\n",
    "fm_sc = 300.0\n",
    "r2_sc = 200.0\n",
    "\n",
    "A2B, A2B_var = test(A, TE)\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(16, 4), nrows=2, ncols=6)\n",
    "\n",
    "# CSE-MR images at each echo\n",
    "mag_ech1 = np.squeeze(np.abs(tf.complex(A[:,0,:,:,0],A[:,0,:,:,1])))\n",
    "pha_ech1 = np.squeeze(np.arctan2(A[:,0,:,:,1],A[:,0,:,:,0]))\n",
    "mag_ech2 = np.squeeze(np.abs(tf.complex(A[:,1,:,:,0],A[:,1,:,:,1])))\n",
    "pha_ech2 = np.squeeze(np.arctan2(A[:,1,:,:,1],A[:,1,:,:,0]))\n",
    "mag_ech3 = np.squeeze(np.abs(tf.complex(A[:,2,:,:,0],A[:,2,:,:,1])))\n",
    "pha_ech3 = np.squeeze(np.arctan2(A[:,2,:,:,1],A[:,2,:,:,0]))\n",
    "\n",
    "# Acquisitions in the first row\n",
    "acq_ech1 = axs[0,0].imshow(mag_ech1, cmap='gray',\n",
    "                      interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,0].set_title('Mag 1st Echo')\n",
    "axs[0,0].axis('off')\n",
    "acq_ech2 = axs[0,1].imshow(pha_ech1/np.pi, cmap='gist_earth',\n",
    "                      interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,1].set_title('Phase 1st Echo')\n",
    "axs[0,1].axis('off')\n",
    "acq_ech3 = axs[0,2].imshow(mag_ech2, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,2].set_title('Mag 2nd Echo')\n",
    "axs[0,2].axis('off')\n",
    "acq_ech4 = axs[0,3].imshow(pha_ech2/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,3].set_title('Phase 2nd Echo')\n",
    "axs[0,3].axis('off')\n",
    "acq_ech5 = axs[0,4].imshow(mag_ech3, cmap='gray',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "axs[0,4].set_title('Mag 3rd Echo')\n",
    "axs[0,4].axis('off')\n",
    "acq_ech6 = axs[0,5].imshow(pha_ech3/np.pi, cmap='gist_earth',\n",
    "                          interpolation='none', vmin=-1, vmax=1)\n",
    "axs[0,5].set_title('Phase 3rd Echo')\n",
    "axs[0,5].axis('off')\n",
    "\n",
    "# A2B maps in the second row\n",
    "w_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1],A2B[:,0,:,:,1:])),axis=0)\n",
    "w_p_aux = np.squeeze(tf.math.atan2(A2B[:,0,:,:,1],A2B[:,0,:,:,0]))\n",
    "f_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,1,:,:,:1],A2B[:,1,:,:,1:])),axis=0)\n",
    "f_p_aux = np.squeeze(tf.math.atan2(A2B[:,1,:,:,1],A2B[:,1,:,:,0]))\n",
    "wf_m_aux = np.squeeze(tf.abs(tf.complex(A2B[:,0,:,:,:1]+A2B[:,1,:,:,:1],A2B[:,0,:,:,1:]+A2B[:,1,:,:,1:])),axis=0)\n",
    "r2_aux = np.squeeze(A2B[:,2,:,:,1])\n",
    "field_aux = np.squeeze(A2B[:,2,:,:,0])\n",
    "\n",
    "PDFF_aux = np.where(f_m_aux >= w_m_aux, f_m_aux/wf_m_aux, 1-(w_m_aux/wf_m_aux))\n",
    "PDFF_aux[np.isnan(PDFF_aux)] = 0.0    \n",
    "\n",
    "W_ok =  axs[1,0].imshow(w_m_aux, cmap='bone',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=axs[1,0])\n",
    "axs[1,0].axis('off')\n",
    "\n",
    "Wp_ok =  axs[1,1].imshow(w_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Wp_ok, ax=axs[1,1])\n",
    "axs[1,1].axis('off')\n",
    "\n",
    "F_ok =  axs[1,2].imshow(f_m_aux, cmap='pink',\n",
    "                        interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=axs[1,2])\n",
    "axs[1,2].axis('off')\n",
    "\n",
    "Fp_ok =  axs[1,3].imshow(f_p_aux/np.pi, cmap='twilight',\n",
    "                        interpolation='none', vmin=-1, vmax=1)\n",
    "fig.colorbar(Fp_ok, ax=axs[1,3])\n",
    "axs[1,3].axis('off')\n",
    "\n",
    "r2_ok = axs[1,4].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                        interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=axs[1,4])\n",
    "axs[1,4].axis('off')\n",
    "\n",
    "field_ok =  axs[1,5].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                            interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=axs[1,5])\n",
    "axs[1,5].axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "tl.make_space_above(axs,topmargin=0.8)\n",
    "fig.set_facecolor(\"none\")\n",
    "plt.show()\n",
    "\n",
    "# Update maps to be saved in MAT file\n",
    "F.append(PDFF_aux*100.0)\n",
    "P.append(np.expand_dims(field_aux*fm_sc, axis=-1))\n",
    "R.append(np.expand_dims(np.concatenate([w_m_aux,f_m_aux],axis=-1), axis=-2))\n",
    "R2.append(np.expand_dims(r2_aux*r2_sc, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cf2a4-b2f1-458a-9a48-0625ed48c4ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if A2B_var is not None:\n",
    "    from matplotlib.colors import LogNorm\n",
    "\n",
    "    W_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,0,:,:,:1],A2B_var[:,0,:,:,1:])),axis=0)\n",
    "    WF_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,1,:,:,:1],A2B_var[:,1,:,:,1:])),axis=0)\n",
    "    F_var = np.squeeze(tf.abs(tf.complex(A2B_var[:,3,:,:,:1],A2B_var[:,3,:,:,1:])),axis=0)\n",
    "    r2s_var = np.squeeze(A2B_var[:,-1,:,:,1:],axis=0)*(r2_sc**2)\n",
    "    field_var = np.squeeze(A2B_var[:,-1,:,:,:1],axis=0)*(fm_sc**2)\n",
    "\n",
    "    PDFF_var = F_var/(f_m_aux**2 + 1e-8)\n",
    "    PDFF_var -= 2 * WF_var / (f_m_aux*(w_m_aux+f_m_aux) + 1e-8)\n",
    "    PDFF_var += (W_var + F_var + 2*WF_var)/(w_m_aux + f_m_aux + 1e-8)\n",
    "    PDFF_var *= f_m_aux**2 / (w_m_aux+f_m_aux + 1e-4)**2 #[W_var,WF_var,F_var]\n",
    "    PDFF_var[PDFF_var<=0.0] = 1e-2\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(15, 4), nrows=2, ncols=5)\n",
    "\n",
    "    # Estimated maps\n",
    "    FF_ok = axs[0,0].imshow(PDFF_aux, cmap='jet',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(FF_ok, ax=axs[0,0])\n",
    "    axs[0,0].axis('off')\n",
    "    W_ok =  axs[0,1].imshow(w_m_aux, cmap='bone',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(W_ok, ax=axs[0,1])\n",
    "    axs[0,1].axis('off')\n",
    "\n",
    "    F_ok =  axs[0,2].imshow(f_m_aux, cmap='pink',\n",
    "                            interpolation='none', vmin=0, vmax=1)\n",
    "    fig.colorbar(F_ok, ax=axs[0,2])\n",
    "    axs[0,2].axis('off')\n",
    "\n",
    "    r2_ok = axs[0,3].imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                            interpolation='none', vmin=0, vmax=r2_sc)\n",
    "    fig.colorbar(r2_ok, ax=axs[0,3])\n",
    "    axs[0,3].axis('off')\n",
    "\n",
    "    field_ok =  axs[0,4].imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                                interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "    fig.colorbar(field_ok, ax=axs[0,4])\n",
    "    axs[0,4].axis('off')\n",
    "    \n",
    "    WF_uq = axs[1,0].matshow(PDFF_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e2))\n",
    "    fig.colorbar(WF_uq, ax=axs[1,0])\n",
    "    axs[1,0].axis('off')\n",
    "\n",
    "    W_uq = axs[1,1].matshow(W_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "    fig.colorbar(W_uq, ax=axs[1,1])\n",
    "    axs[1,1].axis('off')\n",
    "\n",
    "    F_uq = axs[1,2].matshow(F_var, cmap='gnuplot2',\n",
    "                            norm=LogNorm(vmin=1e-2,vmax=1e0))\n",
    "    fig.colorbar(F_uq, ax=axs[1,2])\n",
    "    axs[1,2].axis('off')\n",
    "\n",
    "    r2s_uq=axs[1,3].matshow(r2s_var, cmap='gnuplot',\n",
    "                          norm=LogNorm(vmin=1e0,vmax=1e3))\n",
    "    fig.colorbar(r2s_uq, ax=axs[1,3])\n",
    "    axs[1,3].axis('off')\n",
    "\n",
    "    field_uq = axs[1,4].matshow(field_var, cmap='gnuplot2',\n",
    "                                norm=LogNorm(vmin=1e-5,vmax=1e-2))\n",
    "    fig.colorbar(field_uq, ax=axs[1,4])\n",
    "    axs[1,4].axis('off')\n",
    "\n",
    "    # Update maps to be saved in MAT file\n",
    "    PDFF_vars.append(PDFF_var*1e4)\n",
    "    WF_vars.append(np.expand_dims(np.concatenate([W_var,WF_var,F_var],axis=-1), axis=-2))\n",
    "    R2_vars.append(r2s_var)\n",
    "    FM_vars.append(field_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ac4aa5-4df8-4440-9870-6d252d3c6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_id = file_dir.split('/')[-2].split('_')[-1]\n",
    "listdir = file_dir.split('/')[:-1]\n",
    "listdir.append('res_MP_' + ''.join(model_sel.value.split('-')) + '_' + out_id + '.mat')\n",
    "outpath = '/'.join(listdir)\n",
    "\n",
    "outvars = {'F': np.concatenate(F,axis=-1),\n",
    "           'P': np.concatenate(P,axis=-1),\n",
    "           'R': np.concatenate(R,axis=-2),\n",
    "           'R2':np.concatenate(R2,axis=-1),\n",
    "           'mthd': model_sel.value}\n",
    "\n",
    "if A2B_var is not None:\n",
    "    var_outvars = {'F_var': np.concatenate(PDFF_vars, axis=-1),\n",
    "                   'R_var': np.concatenate(WF_vars, axis=-2),\n",
    "                   'R2_var': np.concatenate(R2_vars, axis=-1),\n",
    "                   'P_var': np.concatenate(FM_vars, axis=-1)}\n",
    "    outvars.update(var_outvars)\n",
    "\n",
    "sio.savemat(outpath, outvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ba7d5-297b-4154-966c-2968dc5dcf71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
