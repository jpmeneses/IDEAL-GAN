import tensorflow as tf

from tensorflow.keras.layers import Layer, InputSpec
import tensorflow.keras.backend as K

# ==============================================================================
# =                             Self-Attention Layer                           =
# ==============================================================================

class SelfAttention(Layer):
 
    def __init__(self, ch, **kwargs):
        super(SelfAttention, self).__init__(**kwargs)
        self.channels = ch
        self.filters_f_g = self.channels // 8
        self.filters_h = self.channels
 
    def build(self, input_shape):
        kernel_shape_f_g = (1, 1) + (self.channels, self.filters_f_g)
        kernel_shape_h = (1, 1) + (self.channels, self.filters_h)
 
        # Create a trainable weight variable for this layer:
        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)
        self.kernel_f = self.add_weight(shape=kernel_shape_f_g,
                                        initializer='glorot_uniform',
                                        name='kernel_f',
                                        trainable=True)
        self.kernel_g = self.add_weight(shape=kernel_shape_f_g,
                                        initializer='glorot_uniform',
                                        name='kernel_g',
                                        trainable=True)
        self.kernel_h = self.add_weight(shape=kernel_shape_h,
                                        initializer='glorot_uniform',
                                        name='kernel_h',
                                        trainable=True)
 
        super(SelfAttention, self).build(input_shape)
        # Set input spec.
        self.input_spec = InputSpec(axes={3: input_shape[-1]})
        self.built = True
 
    def call(self, x):
        def hw_flatten(x):
            return K.reshape(x, shape=[K.shape(x)[0], K.shape(x)[1] * K.shape(x)[2], K.shape(x)[3]])
 
        f = K.conv2d(x,
                     kernel=self.kernel_f,
                     strides=(1, 1), padding='same')  # [bs, h, w, c']
        g = K.conv2d(x,
                     kernel=self.kernel_g,
                     strides=(1, 1), padding='same')  # [bs, h, w, c']
        h = K.conv2d(x,
                     kernel=self.kernel_h,
                     strides=(1, 1), padding='same')  # [bs, h, w, c]
 
        s = K.batch_dot(
            hw_flatten(g), K.permute_dimensions(
                hw_flatten(f), (0, 2, 1)))  # # [bs, N, N]
 
        beta = K.softmax(s, axis=-1)  # attention map
 
        o = K.batch_dot(beta, hw_flatten(h))  # [bs, N, C]
 
        o = K.reshape(o, shape=K.shape(x))  # [bs, h, w, C]
        x = self.gamma * o + x
 
        return x
 
    def compute_output_shape(self, input_shape):
        return input_shape


def AdaIN(content_features, style_features, alpha=1.0, epsilon=1e-5):
    '''
    Normalizes the `content_features` with scaling and offset from `style_features`.
    See "5. Adaptive Instance Normalization" in https://arxiv.org/abs/1703.06868 for details.
    '''
    style_mean, style_variance = tf.nn.moments(style_features, [1], keepdims=True)
    content_mean, content_variance = tf.nn.moments(content_features, [1,2], keepdims=True)
    style_mean = tf.reshape(style_mean, [-1,1,1,style_mean.shape[-1]])
    style_variance = tf.reshape(style_variance, [-1,1,1,style_variance.shape[-1]])
    normalized_content_features = tf.nn.batch_normalization(content_features, content_mean,
                                                            content_variance, style_mean, 
                                                            tf.sqrt(style_variance), epsilon)
    normalized_content_features = alpha * normalized_content_features + (1 - alpha) * content_features
    return normalized_content_features