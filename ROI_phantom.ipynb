{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1706ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import DLlib as dl\n",
    "import pylib as py\n",
    "import tf2lib as tl\n",
    "import wflib as wf\n",
    "\n",
    "import data\n",
    "import mebcrn\n",
    "from keras_unet.models import custom_unet\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import tqdm\n",
    "import h5py\n",
    "import xlsxwriter\n",
    "from skimage.metrics import structural_similarity\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05fad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = 'output/TEaug-002'\n",
    "n_echoes = 6\n",
    "G_model = 'encod-decod'\n",
    "te_input = True\n",
    "n_filters = 32\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fef358",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "############### DIRECTORIES AND FILENAMES ##################\n",
    "############################################################\n",
    "dataset_dir = '../MATLAB/waterFatSignalPhantom/data_out/'\n",
    "dataset_hdf5_1 = 'phantom.hdf5'\n",
    "\n",
    "############################################################\n",
    "################### LOAD DATASET 1 #########################\n",
    "############################################################\n",
    "if G_model == 'complex':\n",
    "    ech_idx = n_echoes\n",
    "else:\n",
    "    ech_idx = n_echoes * 2\n",
    "acqs_1, out_maps_1 = data.load_hdf5(dataset_dir,dataset_hdf5_1, ech_idx, complex_data=(G_model=='complex'))\n",
    "\n",
    "print('Num. Elements- DS1:', len(acqs_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffd7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "################# DATASET PARTITIONS #######################\n",
    "############################################################\n",
    "\n",
    "testX   = acqs_1\n",
    "\n",
    "testY   = out_maps_1\n",
    "\n",
    "# Overall dataset statistics\n",
    "len_dataset,hgt,wdt,d_ech = np.shape(testX)\n",
    "_,_,_,n_out = np.shape(testY)\n",
    "echoes = int(d_ech/2)\n",
    "r2_sc,fm_sc = 200,300\n",
    "\n",
    "print('Acquisition Dimensions:', hgt,wdt)\n",
    "print('Echoes:',echoes)\n",
    "print('Output Maps:',n_out)\n",
    "\n",
    "# Input and output dimensions (testing data)\n",
    "print('Testing input shape:',testX.shape)\n",
    "print('Testing output shape:',testY.shape)\n",
    "\n",
    "A_B_dataset_test = tf.data.Dataset.from_tensor_slices((testX,testY))\n",
    "A_B_dataset_test.batch(batch_size)\n",
    "test_iter = cycle(A_B_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86041f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "if G_model == 'encod-decod':\n",
    "    G_A2B = dl.PM_Generator(input_shape=(hgt,wdt,d_ech),\n",
    "                            te_input=te_input,\n",
    "                            te_shape=(n_echoes,),\n",
    "                            filters=n_filters,\n",
    "                            R2_self_attention=False,\n",
    "                            FM_self_attention=True)\n",
    "elif G_model == 'complex':\n",
    "    G_A2B=dl.PM_complex(input_shape=(hgt,wdt,d_ech),\n",
    "                        filters=n_filters,\n",
    "                        te_input=te_input,\n",
    "                        te_shape=(n_echoes,),\n",
    "                        self_attention=False)\n",
    "elif G_model == 'U-Net':\n",
    "    G_A2B = custom_unet(input_shape=(hgt,wdt,d_ech),\n",
    "                        num_classes=2,\n",
    "                        use_attention=True,\n",
    "                        filters=n_filters)\n",
    "elif G_model == 'MEBCRN':\n",
    "    G_A2B = mebcrn.MEBCRN(input_shape=(hgt,wdt,d_ech),\n",
    "                          n_res_blocks=5,\n",
    "                          n_downsamplings=2,\n",
    "                          filters=24,\n",
    "                          self_attention=True)\n",
    "\n",
    "# restore\n",
    "tl.Checkpoint(dict(G_A2B=G_A2B), py.join(experiment_dir, 'checkpoints')).restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64618c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced-Ideal model\n",
    "@tf.function\n",
    "def sample_A2B(A,TE=None,complex_data=False):\n",
    "    indx_PM =tf.concat([tf.zeros_like(A[:,:,:,:1],dtype=tf.int32),\n",
    "                        tf.ones_like(A[:,:,:,:1],dtype=tf.int32)],axis=-1)\n",
    "    if te_input:\n",
    "        A2B_PM = G_A2B([A,TE], training=False)\n",
    "    else:\n",
    "        A2B_PM = G_A2B(A, training=False)\n",
    "    if G_model == 'U-Net':\n",
    "        orig_shape = A2B_PM.shape\n",
    "        A2B_R2, A2B_FM = tf.dynamic_partition(A2B_PM,indx_PM,num_partitions=2)\n",
    "        A2B_R2 = tf.reshape(A2B_R2,A[:,:,:,:1].shape)\n",
    "        A2B_FM = tf.reshape(A2B_FM,A[:,:,:,:1].shape)\n",
    "        A2B_FM = (A2B_FM - 0.5) * 2\n",
    "        A2B_PM = tf.concat([A2B_R2,A2B_FM],axis=-1)\n",
    "    elif G_model == 'complex':\n",
    "        A2B_R2 = tf.math.real(A2B_PM)\n",
    "        A2B_FM = tf.math.imag(A2B_PM)\n",
    "        A2B_PM = tf.concat([A2B_R2,A2B_FM],axis=-1)\n",
    "    A2B_PM = tf.where(A[:,:,:,:2]!=0.0,A2B_PM,0)\n",
    "    A2B_WF, A2B2A = wf.acq_to_acq(A,A2B_PM,TE,complex_data=complex_data)\n",
    "    A2B = tf.concat([A2B_WF,A2B_PM],axis=-1)\n",
    "    return A2B, A2B2A\n",
    "\n",
    "@tf.function\n",
    "def sample_B2A(B,TE=None,complex_data=False):\n",
    "    indx_PM =tf.concat([tf.zeros_like(B[:,:,:,:1],dtype=tf.int32),\n",
    "                        tf.ones_like(B[:,:,:,:1],dtype=tf.int32)],axis=-1)\n",
    "    B2A = wf.IDEAL_model(B,TE)\n",
    "    if te_input:\n",
    "        B2A2B_PM = G_A2B([B2A,TE], training=False)\n",
    "    else:\n",
    "        B2A2B_PM = G_A2B(B2A, training=False)\n",
    "    if G_model == 'U-Net':\n",
    "        orig_shape = B2A2B_PM.shape\n",
    "        B2A2B_R2, B2A2B_FM = tf.dynamic_partition(A2B_PM,indx_PM,num_partitions=2)\n",
    "        B2A2B_R2 = tf.reshape(B2A2B_R2,B[:,:,:,:1].shape)\n",
    "        B2A2B_FM = tf.reshape(B2A2B_FM,B[:,:,:,:1].shape)\n",
    "        B2A2B_FM = (B2A2B_FM - 0.5) * 2\n",
    "        B2A2B_PM = tf.concat([B2A2B_R2,B2A2B_FM],axis=-1)\n",
    "        B2A2B_PM = tf.reshape(B2A2B_PM,orig_shape)\n",
    "    elif G_model == 'complex':\n",
    "        B2A2B_R2 = tf.math.real(B2A2B_PM)\n",
    "        B2A2B_FM = tf.math.imag(B2A2B_PM)\n",
    "        B2A2B_PM = tf.concat([B2A2B_R2,B2A2B_FM],axis=-1)\n",
    "    B2A2B_WF = wf.get_rho(B2A,B2A2B_PM,TE,complex_data=complex_data)\n",
    "    B2A2B = tf.concat([B2A2B_WF,B2A2B_PM],axis=-1)\n",
    "    return B2A, B2A2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d7b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDWF model\n",
    "# @tf.function\n",
    "# def sample_A2B(A):\n",
    "#     B_mask = tf.concat([A,A],axis=-1)\n",
    "#     A2B = G_A2B(A, training=False)\n",
    "#     A2B = tf.where(B_mask[:,:,:,:6]!=0.0,A2B,0)\n",
    "#     A2B2A = wf.IDEAL_model(A2B)\n",
    "#     return A2B, A2B2A\n",
    "\n",
    "# @tf.function\n",
    "# def sample_B2A(B):\n",
    "#     B2A = wf.IDEAL_model(B)\n",
    "#     B2A2B = G_A2B(B2A, training=False)\n",
    "#     B2A2B = tf.where(B!=0.0,A2B,0)\n",
    "#     return B2A, B2A2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0247e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B = next(test_iter)\n",
    "A = tf.expand_dims(A,axis=0)\n",
    "B = tf.expand_dims(B,axis=0)\n",
    "if te_input:\n",
    "    te_orig = wf.gen_TEvar(n_echoes,batch_size,orig=True)\n",
    "    A2B, A2B2A = sample_A2B(A, TE=te_orig, complex_data=(G_model=='complex'))\n",
    "else:\n",
    "    A2B, A2B2A = sample_A2B(A, complex_data=(G_model=='complex'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c4da3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ((ax1,ax2,ax3,ax4),(ax5,ax6,ax7,ax8))=plt.subplots(figsize=(14, 6),\n",
    "                                                        nrows=2, ncols=4)\n",
    "# Ground truth in the first row\n",
    "w_aux = np.squeeze(np.abs(tf.complex(A2B[:,:,:,0],A2B[:,:,:,1])))\n",
    "W_ok = ax1.imshow(w_aux, cmap='bone',\n",
    "                  interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_ok, ax=ax1)\n",
    "ax1.axis('off')\n",
    "\n",
    "f_aux = np.squeeze(np.abs(tf.complex(A2B[:,:,:,2],A2B[:,:,:,3])))\n",
    "F_ok = ax2.imshow(f_aux, cmap='pink',\n",
    "                  interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_ok, ax=ax2)\n",
    "ax2.axis('off')\n",
    "\n",
    "r2_aux = np.squeeze(A2B[:,:,:,4])\n",
    "r2_ok = ax3.imshow(r2_aux*r2_sc, cmap='copper',\n",
    "                   interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_ok, ax=ax3)\n",
    "ax3.axis('off')\n",
    "\n",
    "field_aux = np.squeeze(A2B[:,:,:,5]) \n",
    "field_ok = ax4.imshow(field_aux*fm_sc, cmap='twilight',\n",
    "                      interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_ok, ax=ax4)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Computed maps in the second row\n",
    "wn_aux = np.squeeze(np.abs(tf.complex(B[:,:,:,0],B[:,:,:,1])))\n",
    "W_unet = ax5.imshow(wn_aux, cmap='bone',\n",
    "                    interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(W_unet, ax=ax5)\n",
    "ax5.axis('off')\n",
    "\n",
    "fn_aux = np.squeeze(np.abs(tf.complex(B[:,:,:,2],B[:,:,:,3])))\n",
    "F_unet = ax6.imshow(fn_aux, cmap='pink',\n",
    "                    interpolation='none', vmin=0, vmax=1)\n",
    "fig.colorbar(F_unet, ax=ax6)\n",
    "ax6.axis('off')\n",
    "\n",
    "r2n_aux = np.squeeze(B[:,:,:,4])\n",
    "r2_unet = ax7.imshow(r2n_aux*r2_sc, cmap='copper',\n",
    "                     interpolation='none', vmin=0, vmax=r2_sc)\n",
    "fig.colorbar(r2_unet, ax=ax7)\n",
    "ax7.axis('off')\n",
    "\n",
    "fieldn_aux = np.squeeze(B[:,:,:,5])\n",
    "field_unet = ax8.imshow(fieldn_aux*fm_sc, cmap='twilight',\n",
    "                        interpolation='none', vmin=-fm_sc/2, vmax=fm_sc/2)\n",
    "fig.colorbar(field_unet, ax=ax8)\n",
    "ax8.axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISPLAY ERROR (4 OUTPUTS)\n",
    "fig_err, (ix1,ix2,ix3,ix4) = plt.subplots(figsize=(14, 3), nrows=1, ncols=4)\n",
    "\n",
    "# Ground truth in the first row\n",
    "w_err = np.abs(w_aux-wn_aux)\n",
    "Wn_err = ix1.imshow(w_err, cmap='gray',\n",
    "                    interpolation='none', vmin=0, vmax=0.5)\n",
    "fig_err.colorbar(Wn_err, ax=ix1)\n",
    "# ix1.set_title('Water Error')\n",
    "ix1.axis('off')\n",
    "f_err = np.abs(f_aux-fn_aux)\n",
    "Fn_err = ix2.imshow(f_err, cmap='gray',\n",
    "                    interpolation='none', vmin=0, vmax=0.5)\n",
    "fig_err.colorbar(Fn_err, ax=ix2)\n",
    "# ix2.set_title('Fat Error')\n",
    "ix2.axis('off')\n",
    "r2_err = np.abs(r2_aux-r2n_aux)*r2_sc\n",
    "r2n_err = ix3.imshow(r2_err, cmap='gray',\n",
    "                     interpolation='none', vmin=0, vmax=r2_sc/2)\n",
    "fig_err.colorbar(r2n_err, ax=ix3)\n",
    "# ix3.set_title('R2* Error')\n",
    "ix3.axis('off')\n",
    "field_err = np.abs(field_aux-fieldn_aux)*fm_sc\n",
    "fieldn_err = ix4.imshow(field_err, cmap='gray',\n",
    "                        interpolation='none', vmin=0, vmax=fm_sc/8)\n",
    "fig_err.colorbar(fieldn_err, ax=ix4)\n",
    "# ix4.set_title('Field Error')\n",
    "ix4.axis('off')\n",
    "\n",
    "plt.subplots_adjust(top=1,bottom=0,right=1,left=0,hspace=0.1,wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_w = np.mean(tf.abs(w_aux-wn_aux), axis=(0,1))\n",
    "MAE_f = np.mean(tf.abs(f_aux-fn_aux), axis=(0,1))\n",
    "MAE_r2 = np.mean(tf.abs(r2_aux-r2n_aux), axis=(0,1))\n",
    "MAE_fm = np.mean(tf.abs(field_aux-fieldn_aux), axis=(0,1))\n",
    "print('MAEs:',np.round([MAE_w,MAE_f,MAE_r2,MAE_fm],5))\n",
    "print('R2* MAE [1/s]:',np.round(200*MAE_r2,5))\n",
    "print('Field Map MAE [Hz]:',np.round(300*MAE_fm,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11045380",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ssim = structural_similarity(w_aux,wn_aux,multichannel=False)\n",
    "f_ssim = structural_similarity(f_aux,fn_aux,multichannel=False)\n",
    "r2_ssim = structural_similarity(r2_aux,r2n_aux,multichannel=False)\n",
    "fm_ssim = structural_similarity(field_aux,fieldn_aux,multichannel=False)\n",
    "print('SSIMs:',np.round([w_ssim,f_ssim,r2_ssim,fm_ssim],5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1a5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Truth PDFF\n",
    "PDFF_res = f_aux/(w_aux+f_aux)\n",
    "PDFF_res[np.isnan(PDFF_res)] = 0.0\n",
    "\n",
    "# Model Measured PDFF\n",
    "PDFF_gt = fn_aux/(wn_aux+fn_aux)\n",
    "PDFF_gt[np.isnan(PDFF_gt)] = 0.0\n",
    "\n",
    "# Segmentation rectangle (ref. values for test data NÂ°105)\n",
    "verts_list = {1:   (69,109),#ok\n",
    "              2:   (61,89),#ok\n",
    "              3:   (69,68),#ok\n",
    "              4:   (90,60),#ok\n",
    "              5:  (110,68),#ok\n",
    "              6:  (119,89),#ok\n",
    "              7:  (110,109)}#ok\n",
    "\n",
    "left_x,sup_y = verts_list[7]\n",
    "rect_hgt,rect_wdt = 13,13\n",
    "rect_gt = patches.Rectangle((left_x,sup_y),rect_wdt,rect_hgt,\n",
    "                            linewidth=1,edgecolor='y',facecolor='none')\n",
    "rect_res = patches.Rectangle((left_x,sup_y),rect_wdt,rect_hgt,\n",
    "                             linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "fig_pdff, (ex1,ex2) = plt.subplots(figsize=(10, 4), nrows=1, ncols=2)\n",
    "\n",
    "disp_pdff_ok = ex1.imshow(PDFF_gt, cmap='bone',\n",
    "                          interpolation='none', vmin=0, vmax=1)\n",
    "fig_pdff.colorbar(disp_pdff_ok, ax=ex1)\n",
    "# ex1.set_title('PDFF Ground Truth',{'fontsize':15})\n",
    "# ex1.add_patch(rect_gt)\n",
    "ex1.axis('off')\n",
    "\n",
    "disp_pdff_res = ex2.imshow(PDFF_res, cmap='bone',\n",
    "                           interpolation='none', vmin=0, vmax=1)\n",
    "fig_pdff.colorbar(disp_pdff_res, ax=ex2)\n",
    "# ex2.set_title('Resulting PDFF',{'fontsize':15})\n",
    "# ex2.add_patch(rect_res)\n",
    "ex2.axis('off')\n",
    "\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                    hspace = 0.1, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "plt.gca().xaxis.set_major_locator(plt.NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(plt.NullLocator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36783243",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1,r2 = sup_y,(sup_y+rect_hgt)\n",
    "c1,c2 = left_x,(left_x+rect_wdt)\n",
    "PDFF_gt_crop = PDFF_gt[r1:r2,c1:c2]\n",
    "PDFF_res_crop = PDFF_res[r1:r2,c1:c2]\n",
    "\n",
    "print('Median of PDFF in the segmented region:')\n",
    "print('Ground-Truth:\\t',np.median(PDFF_gt_crop))\n",
    "print('Model result:\\t',np.median(PDFF_res_crop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c3ef2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PDFF_res_all = np.array([])\n",
    "PDFF_gt_all = np.array([])\n",
    "rect_hgt,rect_wdt = 13,13\n",
    "for k in verts_list:\n",
    "    left_x,sup_y = verts_list[k]\n",
    "    r1,r2 = sup_y,(sup_y+rect_hgt)\n",
    "    c1,c2 = left_x,(left_x+rect_wdt)\n",
    "    # PDFF crops - magnitude model results\n",
    "    # w_all = all_test_ans[(k_prev+4):(k-4),r1:r2,c1:c2,0]\n",
    "    # f_all = all_test_ans[(k_prev+4):(k-4),r1:r2,c1:c2,1]\n",
    "    # PDFF crops - complex model results\n",
    "    w_all = np.abs(tf.complex(A2B[:,r1:r2,c1:c2,0],\n",
    "                              A2B[:,r1:r2,c1:c2,1]))\n",
    "    f_all = np.abs(tf.complex(A2B[:,r1:r2,c1:c2,2],\n",
    "                              A2B[:,r1:r2,c1:c2,3]))\n",
    "    PDFF_res_aux = np.median(f_all/(f_all+w_all),axis=(1,2))\n",
    "    PDFF_res_all = np.concatenate((PDFF_res_all,PDFF_res_aux),axis=0)\n",
    "    # PDFF crops - GT magnitude results\n",
    "    # w_all_gt = testY[(k_prev+4):(k-4):,r1:r2,c1:c2,0]\n",
    "    # f_all_gt = testY[(k_prev+4):(k-4),r1:r2,c1:c2,1]\n",
    "    # PDFF crops - GT complex results\n",
    "    w_all_gt = np.abs(tf.complex(B[:,r1:r2,c1:c2,0],\n",
    "                                 B[:,r1:r2,c1:c2,1]))\n",
    "    f_all_gt = np.abs(tf.complex(B[:,r1:r2,c1:c2,2],\n",
    "                                 B[:,r1:r2,c1:c2,3]))\n",
    "    PDFF_gt_aux = np.median(f_all_gt/(f_all_gt+w_all_gt),axis=(1,2))\n",
    "    PDFF_gt_all = np.concatenate((PDFF_gt_all,PDFF_gt_aux),axis=0)\n",
    "\n",
    "# Compute error\n",
    "PDFF_err_list = PDFF_res_all-PDFF_gt_all\n",
    "print('PDFF estimations:',np.round(PDFF_res_all,5))\n",
    "print('Ground-truth:',np.round(PDFF_gt_all,5))\n",
    "print('Errors:',np.round(PDFF_err_list,5))\n",
    "\n",
    "# PDFF crops mean error\n",
    "PDFF_err_mean = np.mean((PDFF_err_list))\n",
    "PDFF_err_std = np.std((PDFF_err_list))\n",
    "print('Mean PDFF error:',np.round(PDFF_err_mean*100,2),\n",
    "      '+-',np.round(PDFF_err_std*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_res_all = np.array([])\n",
    "r2_gt_all = np.array([])\n",
    "for k in verts_list:\n",
    "    left_x,sup_y = verts_list[k]\n",
    "    r1,r2 = sup_y,(sup_y+rect_hgt)\n",
    "    c1,c2 = left_x,(left_x+rect_wdt)\n",
    "    # R2* crops - complex model results\n",
    "    r2_all = A2B[:,r1:r2,c1:c2,4]*r2_sc\n",
    "    r2_res_aux = np.mean(r2_all,axis=(1,2))\n",
    "    r2_res_all = np.concatenate((r2_res_all,r2_res_aux),axis=0)\n",
    "    # R2* crops - GT complex results\n",
    "    r2_all_gt = B[:,r1:r2,c1:c2,4]*r2_sc\n",
    "    r2_gt_aux = np.mean(r2_all_gt,axis=(1,2))\n",
    "    r2_gt_all = np.concatenate((r2_gt_all,r2_gt_aux),axis=0)\n",
    "\n",
    "# Compute error\n",
    "r2_err_list = r2_res_all-r2_gt_all\n",
    "print('R2* estimations:',r2_res_all)\n",
    "print('Ground-truth:',r2_gt_all)\n",
    "print('Errors:\\n',r2_err_list)\n",
    "\n",
    "# R2* crops mean error\n",
    "r2_err_mean = np.mean((r2_err_list))\n",
    "r2_err_std = np.std((r2_err_list))\n",
    "print('Mean R2* error:',np.round(r2_err_mean,2),\n",
    "      '+-',np.round(r2_err_std,2),'[1/s]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
